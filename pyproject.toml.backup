[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "llm_call"
version = "1.0.0" # Consider incrementing as you make changes, e.g., "1.0.1" or "1.1.0"
description = "Experiment with Litellm and Claude, including a local proxy for Claude CLI."
authors = [{ name = "Graham Anderson", email = "graham@grahama.co" }]
requires-python = "~=3.10" # Your PoC script uses f-strings with assignment expressions (:=) if any, so >=3.8 is fine. 3.10 is good.
readme = "README.md"
license = "GPL-3.0-or-later" # Ensure this aligns with any licenses of dependencies if distributing.
keywords = [
    "llm",
    "litellm",
    "claude",
    "proxy",
    "fastapi",
    "anthropic"
]
# Core dependencies needed for your llm_call package AND the PoC script
dependencies = [
    "litellm>=1.34.20", # Assuming you need it for the non-proxy path, check latest stable
    "httpx>=0.27.0", # For async HTTP calls in PoC and potentially core
    "loguru>=0.7.2",
    "python-dotenv>=1.0.0",
    "tenacity>=8.2.3", # From your PoC's llm_call.py
    "fastapi>=0.110.0", # Needed for the PoC's embedded server & core/api.py
    "uvicorn[standard]>=0.29.0", # Needed to run FastAPI (standard includes common extras)
    "deepmerge>=1.1.0", # From your PoC's llm_call.py
    "pydantic>=2.0", # From your PoC's llm_call.py and core/base.py
    # Dependencies below were from your original list, review if all are strictly needed
    # by the llm_call package itself, or if some are for other experiments.
    "google-cloud-aiplatform>=1.38.1", # If you use Vertex AI via LiteLLM
    "pillow>=10.0.0", # For multimodal if you process images
    "redis>=5.0.0", # For LiteLLM Redis cache
    "torch>=2.0.0", # Large dependency, ensure it's needed by llm_call. For multimodal/transformers.
    "transformers>=4.30.0", # Large dependency, ensure it's needed. For multimodal/token counting.
    "json-repair>=0.46.0",
    "llm>=0.25",
    "llm-gemini>=0.20",
    "files-to-prompt>=0.6",
    "typer>=0.9.0", # CLI framework for slash command generation
    "pytest>=8.3.5",
    "wikipedia>=1.4.0",
    "wikipedia-api>=0.8.1",
]

[project.optional-dependencies]
# These seem to be for document processing, separate from core LLM calls. Good as optional.
full = [
    "mammoth>=1.7.0", # Updated to avoid <2 if 1.9 has issues
    "openpyxl>=3.1.2",
    "python-pptx>=0.6.23",
    "ebooklib>=0.18",
    "weasyprint>=61.0", # Updated version
]

# 'dev' group is better under [project.optional-dependencies] for modern pip/uv
# or use [tool.hatch.envs.default.features] if using Hatch environments extensively.
# Let's keep it under optional-dependencies for broader compatibility.
dev = [
    "jupyter>=1.0.0",
    "datasets>=2.18.0",
    "streamlit>=1.33.0",
    # fastapi & uvicorn are now in core dependencies as the PoC needs them to run its own server
    "python-multipart>=0.0.9", # For FastAPI file uploads, if needed
    "pytest>=8.0.0",
    "pytest-mock>=3.12.0",
    "pytest-asyncio", # For testing async code with pytest
    "apted==1.0.3",
    "distance==0.1.3",
    "lxml>=5.1.0", # Updated version
    "tabulate>=0.9.0",
    "latex2mathml>=3.77.0",
    "playwright>=1.42.0", # Updated version
    "ruff", # For linting and formatting
]

[project.urls]
Repository = "https://github.com/grahama1970/llm_call"

[project.scripts]
# Main CLI entry point
llm-cli = "llm_call.cli.main:app"

# PoC script entry points
llm-call-poc = "llm_call.proof_of_concept.llm_call:main" # Original
llm-call-claude-cli-poc = "llm_call.proof_of_concept.claude_cli_via_api_poc:async_main_runner_wrapper" # Example for the new one

# Wrapper function for the new PoC if you want to make it a script
# In claude_cli_via_api_poc.py, you would add:
# def async_main_runner_wrapper():
#     asyncio.run(main_self_contained_poc())


# --- Hatch Specific Configuration ---
[tool.hatch.version]
path = "src/llm_call/__init__.py" # Assuming you put __version__ = "1.0.0" in src/llm_call/__init__.py

[tool.hatch.envs.default]
# This tells hatch that if someone activates the default dev env,
# the 'dev' optional dependencies should be installed.
features = ["dev"]
# This is crucial for Hatch to correctly set up sys.path in its managed environments
# so that `import llm_call` works when `llm_call` is in `src/`.
python = "python" # Or your specific Python version like "3.10"
[tool.hatch.envs.default.scripts]
# Example of a custom script you can run with `hatch run default:test-claude-poc`
test-claude-poc = "python src/llm_call/proof_of_concept/claude_cli_via_api_poc.py"


[tool.hatch.build.targets.sdist]
# For sdist, you usually include everything in src, plus other files.
include = [
    "/src", # Include the whole src directory
    "/tests", # If you have tests
    "README.md",
    "LICENSE", # If you have a license file
    # Add other top-level files or directories needed for sdist
]
# Exclude can be useful too
# exclude = []

[tool.hatch.build.targets.wheel]
# This tells Hatch where to find the actual package code for the wheel.
# If your package `llm_call` is directly inside `src/`, this is correct.
packages = ["src/llm_call"]
# If you had other data files within src/llm_call to include in the wheel:
# [tool.hatch.build.targets.wheel.force-include]
# "src/llm_call/data/" = "llm_call/data"

# --- Ruff Linter/Formatter Configuration (Example) ---
[tool.ruff]
line-length = 120
select = ["E", "W", "F", "I", "UP", "C4", "B", "A", "RUF"] # Example selections
ignore = ["E501"] # Ignore line too long if Ruff handles it

[tool.ruff.lint.isort]
known-first-party = ["llm_call"]
