{"created": 1749141922.9662864, "duration": 64.21188402175903, "exitcode": 1, "root": "/home/graham/workspace/experiments/youtube_transcripts", "environment": {}, "summary": {"passed": 74, "failed": 23, "skipped": 8, "error": 17, "total": 122, "collected": 122}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "tests", "type": "Package"}]}, {"nodeid": "tests/agents/test_agents.py::TestAgentSystem", "outcome": "passed", "result": [{"nodeid": "tests/agents/test_agents.py::TestAgentSystem::test_agent_manager_task_submission", "type": "Coroutine", "lineno": 37}, {"nodeid": "tests/agents/test_agents.py::TestAgentSystem::test_search_optimizer_agent_execution", "type": "Coroutine", "lineno": 63}, {"nodeid": "tests/agents/test_agents.py::TestAgentSystem::test_agent_progress_tracking", "type": "Coroutine", "lineno": 91}, {"nodeid": "tests/agents/test_agents.py::TestAgentSystem::test_agent_message_passing", "type": "Coroutine", "lineno": 112}, {"nodeid": "tests/agents/test_agents.py::TestAgentSystem::test_concurrent_agent_execution", "type": "Coroutine", "lineno": 145}, {"nodeid": "tests/agents/test_agents.py::TestAgentSystem::test_agent_error_handling", "type": "Coroutine", "lineno": 168}, {"nodeid": "tests/agents/test_agents.py::TestAgentSystem::test_task_cancellation", "type": "Coroutine", "lineno": 187}]}, {"nodeid": "tests/agents/test_agents.py", "outcome": "passed", "result": [{"nodeid": "tests/agents/test_agents.py::TestAgentSystem", "type": "Class"}]}, {"nodeid": "tests/agents", "outcome": "passed", "result": [{"nodeid": "tests/agents/test_agents.py", "type": "Module"}]}, {"nodeid": "tests/cli", "outcome": "passed", "result": []}, {"nodeid": "tests/core/test_database.py::TestDatabaseOperations", "outcome": "passed", "result": [{"nodeid": "tests/core/test_database.py::TestDatabaseOperations::test_initialize_database_creates_tables", "type": "Function", "lineno": 37}, {"nodeid": "tests/core/test_database.py::TestDatabaseOperations::test_add_transcript_with_real_data", "type": "Function", "lineno": 56}, {"nodeid": "tests/core/test_database.py::TestDatabaseOperations::test_search_transcripts_with_special_characters", "type": "Function", "lineno": 90}, {"nodeid": "tests/core/test_database.py::TestDatabaseOperations::test_search_ranking_with_real_data", "type": "Function", "lineno": 128}, {"nodeid": "tests/core/test_database.py::TestDatabaseOperations::test_channel_filtering", "type": "Function", "lineno": 170}, {"nodeid": "tests/core/test_database.py::TestDatabaseOperations::test_cleanup_old_transcripts", "type": "Function", "lineno": 193}]}, {"nodeid": "tests/core/test_database.py", "outcome": "passed", "result": [{"nodeid": "tests/core/test_database.py::TestDatabaseOperations", "type": "Class"}]}, {"nodeid": "tests/core/test_youtube.py::TestRealYouTube", "outcome": "passed", "result": [{"nodeid": "tests/core/test_youtube.py::TestRealYouTube::test_extract_video_id", "type": "Function", "lineno": 23}, {"nodeid": "tests/core/test_youtube.py::TestRealYouTube::test_fetch_real_transcript", "type": "Function", "lineno": 37}, {"nodeid": "tests/core/test_youtube.py::TestRealYouTube::test_get_channel_videos_real", "type": "Function", "lineno": 54}, {"nodeid": "tests/core/test_youtube.py::TestRealYouTube::test_process_channels_with_empty_list", "type": "Function", "lineno": 78}]}, {"nodeid": "tests/core/test_youtube.py", "outcome": "passed", "result": [{"nodeid": "tests/core/test_youtube.py::TestRealYouTube", "type": "Class"}]}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestScientificPipeline", "outcome": "passed", "result": [{"nodeid": "tests/core/utils/test_scientific_extractors.py::TestScientificPipeline::test_pipeline_initialization", "type": "Function", "lineno": 23}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestScientificPipeline::test_citation_detection", "type": "Function", "lineno": 31}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestScientificPipeline::test_institution_recognition", "type": "Function", "lineno": 48}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestScientificPipeline::test_technical_term_extraction", "type": "Function", "lineno": 62}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestScientificPipeline::test_speaker_extraction_in_pipeline", "type": "Function", "lineno": 79}]}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestCitationDetector", "outcome": "passed", "result": [{"nodeid": "tests/core/utils/test_scientific_extractors.py::TestCitationDetector::test_arxiv_detection", "type": "Function", "lineno": 97}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestCitationDetector::test_doi_detection", "type": "Function", "lineno": 113}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestCitationDetector::test_author_year_detection", "type": "Function", "lineno": 128}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestCitationDetector::test_citation_formatting", "type": "Function", "lineno": 144}]}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestSpeakerExtractor", "outcome": "passed", "result": [{"nodeid": "tests/core/utils/test_scientific_extractors.py::TestSpeakerExtractor::test_introduction_extraction", "type": "Function", "lineno": 176}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestSpeakerExtractor::test_labeled_speaker_extraction", "type": "Function", "lineno": 195}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestSpeakerExtractor::test_speaker_deduplication", "type": "Function", "lineno": 217}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestSpeakerExtractor::test_speaker_formatting", "type": "Function", "lineno": 231}]}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestContentClassifier", "outcome": "passed", "result": [{"nodeid": "tests/core/utils/test_scientific_extractors.py::TestContentClassifier::test_content_type_classification", "type": "Function", "lineno": 258}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestContentClassifier::test_academic_level_classification", "type": "Function", "lineno": 291}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestContentClassifier::test_topic_extraction", "type": "Function", "lineno": 324}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestContentClassifier::test_quality_indicators", "type": "Function", "lineno": 343}]}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestMetadataExtractor", "outcome": "passed", "result": [{"nodeid": "tests/core/utils/test_scientific_extractors.py::TestMetadataExtractor::test_full_extraction", "type": "Function", "lineno": 373}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestMetadataExtractor::test_batch_extraction", "type": "Function", "lineno": 410}]}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestIntegration", "outcome": "passed", "result": [{"nodeid": "tests/core/utils/test_scientific_extractors.py::TestIntegration::test_end_to_end_extraction", "type": "Function", "lineno": 437}]}, {"nodeid": "tests/core/utils/test_scientific_extractors.py", "outcome": "passed", "result": [{"nodeid": "tests/core/utils/test_scientific_extractors.py::TestScientificPipeline", "type": "Class"}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestCitationDetector", "type": "Class"}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestSpeakerExtractor", "type": "Class"}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestContentClassifier", "type": "Class"}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestMetadataExtractor", "type": "Class"}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestIntegration", "type": "Class"}]}, {"nodeid": "tests/core/utils", "outcome": "passed", "result": [{"nodeid": "tests/core/utils/test_scientific_extractors.py", "type": "Module"}]}, {"nodeid": "tests/core", "outcome": "passed", "result": [{"nodeid": "tests/core/test_database.py", "type": "Module"}, {"nodeid": "tests/core/test_youtube.py", "type": "Module"}, {"nodeid": "tests/core/utils", "type": "Package"}]}, {"nodeid": "tests/integration/test_arangodb_features.py::TestArangoDBIntegration", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_arangodb_features.py::TestArangoDBIntegration::test_store_and_retrieve_with_embeddings", "type": "Coroutine", "lineno": 170}, {"nodeid": "tests/integration/test_arangodb_features.py::TestArangoDBIntegration::test_hybrid_search", "type": "Coroutine", "lineno": 190}, {"nodeid": "tests/integration/test_arangodb_features.py::TestArangoDBIntegration::test_citation_network", "type": "Coroutine", "lineno": 209}, {"nodeid": "tests/integration/test_arangodb_features.py::TestArangoDBIntegration::test_speaker_relationships", "type": "Coroutine", "lineno": 229}, {"nodeid": "tests/integration/test_arangodb_features.py::TestArangoDBIntegration::test_entity_linking", "type": "Coroutine", "lineno": 264}, {"nodeid": "tests/integration/test_arangodb_features.py::TestArangoDBIntegration::test_find_related_videos", "type": "Coroutine", "lineno": 302}, {"nodeid": "tests/integration/test_arangodb_features.py::TestArangoDBIntegration::test_research_analyzer_integration", "type": "Coroutine", "lineno": 320}]}, {"nodeid": "tests/integration/test_arangodb_features.py", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_arangodb_features.py::TestArangoDBIntegration", "type": "Class"}]}, {"nodeid": "tests/integration/test_arxiv_youtube_integration.py::TestArxivYouTubeIntegration", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_arxiv_youtube_integration.py::TestArxivYouTubeIntegration::test_citation_validation_pipeline", "type": "Coroutine", "lineno": 86}, {"nodeid": "tests/integration/test_arxiv_youtube_integration.py::TestArxivYouTubeIntegration::test_research_enhancement_pipeline", "type": "Coroutine", "lineno": 113}, {"nodeid": "tests/integration/test_arxiv_youtube_integration.py::TestArxivYouTubeIntegration::test_cross_reference_search", "type": "Function", "lineno": 142}, {"nodeid": "tests/integration/test_arxiv_youtube_integration.py::TestArxivYouTubeIntegration::test_evidence_based_validation", "type": "Coroutine", "lineno": 162}, {"nodeid": "tests/integration/test_arxiv_youtube_integration.py::TestArxivYouTubeIntegration::test_unified_metadata_extraction", "type": "Function", "lineno": 201}, {"nodeid": "tests/integration/test_arxiv_youtube_integration.py::TestArxivYouTubeIntegration::test_research_discovery_workflow", "type": "Coroutine", "lineno": 230}]}, {"nodeid": "tests/integration/test_arxiv_youtube_integration.py", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_arxiv_youtube_integration.py::TestArxivYouTubeIntegration", "type": "Class"}]}, {"nodeid": "tests/integration/test_database_adapter.py::TestReportGenerator", "outcome": "passed", "result": []}, {"nodeid": "tests/integration/test_database_adapter.py::TestSQLiteBackend", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_database_adapter.py::TestSQLiteBackend::test_sqlite_initialization", "type": "Coroutine", "lineno": 123}, {"nodeid": "tests/integration/test_database_adapter.py::TestSQLiteBackend::test_sqlite_store_and_retrieve", "type": "Coroutine", "lineno": 161}, {"nodeid": "tests/integration/test_database_adapter.py::TestSQLiteBackend::test_sqlite_search", "type": "Coroutine", "lineno": 199}, {"nodeid": "tests/integration/test_database_adapter.py::TestSQLiteBackend::test_sqlite_evidence_finding", "type": "Coroutine", "lineno": 237}]}, {"nodeid": "tests/integration/test_database_adapter.py::TestDatabaseAdapter", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_database_adapter.py::TestDatabaseAdapter::test_auto_detection", "type": "Coroutine", "lineno": 271}, {"nodeid": "tests/integration/test_database_adapter.py::TestDatabaseAdapter::test_forced_backends", "type": "Coroutine", "lineno": 296}, {"nodeid": "tests/integration/test_database_adapter.py::TestDatabaseAdapter::test_adapter_interface", "type": "Coroutine", "lineno": 329}]}, {"nodeid": "tests/integration/test_database_adapter.py::TestDatabaseConfig", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_database_adapter.py::TestDatabaseConfig::test_config_from_env", "type": "Function", "lineno": 372}, {"nodeid": "tests/integration/test_database_adapter.py::TestDatabaseConfig::test_backend_config_generation", "type": "Function", "lineno": 405}]}, {"nodeid": "tests/integration/test_database_adapter.py", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_database_adapter.py::TestReportGenerator", "type": "Class"}, {"nodeid": "tests/integration/test_database_adapter.py::TestSQLiteBackend", "type": "Class"}, {"nodeid": "tests/integration/test_database_adapter.py::TestDatabaseAdapter", "type": "Class"}, {"nodeid": "tests/integration/test_database_adapter.py::TestDatabaseConfig", "type": "Class"}, {"nodeid": "tests/integration/test_database_adapter.py::test_full_integration_flow", "type": "Coroutine", "lineno": 430}]}, {"nodeid": "tests/integration", "outcome": "passed", "result": [{"nodeid": "tests/integration/test_arangodb_features.py", "type": "Module"}, {"nodeid": "tests/integration/test_arxiv_youtube_integration.py", "type": "Module"}, {"nodeid": "tests/integration/test_database_adapter.py", "type": "Module"}]}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized", "outcome": "passed", "result": [{"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_module_attributes", "type": "Coroutine", "lineno": 30}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_standardized_response_format", "type": "Coroutine", "lineno": 45}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_error_response_format", "type": "Coroutine", "lineno": 71}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_fetch_transcript_missing_params", "type": "Coroutine", "lineno": 91}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_search_transcripts", "type": "Coroutine", "lineno": 105}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_get_channel_videos", "type": "Coroutine", "lineno": 126}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_extract_keywords_with_transcript", "type": "Coroutine", "lineno": 145}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_extract_keywords_with_video_id", "type": "Coroutine", "lineno": 164}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_summarize_video_with_id", "type": "Coroutine", "lineno": 180}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_summarize_video_missing_params", "type": "Coroutine", "lineno": 200}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_multiple_actions_sequence", "type": "Coroutine", "lineno": 215}]}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py", "outcome": "passed", "result": [{"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized", "type": "Class"}]}, {"nodeid": "tests/level_0", "outcome": "passed", "result": [{"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py", "type": "Module"}]}, {"nodeid": "tests/mcp/test_prompts.py::TestPromptRegistry", "outcome": "passed", "result": [{"nodeid": "tests/mcp/test_prompts.py::TestPromptRegistry::test_registry_creation", "type": "Function", "lineno": 22}, {"nodeid": "tests/mcp/test_prompts.py::TestPromptRegistry::test_register_prompt", "type": "Function", "lineno": 29}, {"nodeid": "tests/mcp/test_prompts.py::TestPromptRegistry::test_get_prompt", "type": "Function", "lineno": 51}, {"nodeid": "tests/mcp/test_prompts.py::TestPromptRegistry::test_execute_prompt", "type": "Coroutine", "lineno": 66}, {"nodeid": "tests/mcp/test_prompts.py::TestPromptRegistry::test_execute_with_registry_injection", "type": "Coroutine", "lineno": 78}, {"nodeid": "tests/mcp/test_prompts.py::TestPromptRegistry::test_prompt_parameters_extraction", "type": "Function", "lineno": 91}]}, {"nodeid": "tests/mcp/test_prompts.py::TestMCPPromptDecorator", "outcome": "passed", "result": [{"nodeid": "tests/mcp/test_prompts.py::TestMCPPromptDecorator::test_decorator_registration", "type": "Function", "lineno": 124}, {"nodeid": "tests/mcp/test_prompts.py::TestMCPPromptDecorator::test_decorator_with_examples", "type": "Function", "lineno": 146}]}, {"nodeid": "tests/mcp/test_prompts.py::TestFormatPromptResponse", "outcome": "passed", "result": [{"nodeid": "tests/mcp/test_prompts.py::TestFormatPromptResponse::test_basic_formatting", "type": "Function", "lineno": 169}, {"nodeid": "tests/mcp/test_prompts.py::TestFormatPromptResponse::test_formatting_with_next_steps", "type": "Function", "lineno": 176}, {"nodeid": "tests/mcp/test_prompts.py::TestFormatPromptResponse::test_formatting_with_suggestions", "type": "Function", "lineno": 188}, {"nodeid": "tests/mcp/test_prompts.py::TestFormatPromptResponse::test_formatting_with_data", "type": "Function", "lineno": 203}]}, {"nodeid": "tests/mcp/test_prompts.py::TestMCPPromptSchema", "outcome": "passed", "result": [{"nodeid": "tests/mcp/test_prompts.py::TestMCPPromptSchema::test_prompt_to_schema", "type": "Function", "lineno": 220}, {"nodeid": "tests/mcp/test_prompts.py::TestMCPPromptSchema::test_registry_to_schema", "type": "Function", "lineno": 241}]}, {"nodeid": "tests/mcp/test_prompts.py", "outcome": "passed", "result": [{"nodeid": "tests/mcp/test_prompts.py::TestPromptRegistry", "type": "Class"}, {"nodeid": "tests/mcp/test_prompts.py::TestMCPPromptDecorator", "type": "Class"}, {"nodeid": "tests/mcp/test_prompts.py::TestFormatPromptResponse", "type": "Class"}, {"nodeid": "tests/mcp/test_prompts.py::TestMCPPromptSchema", "type": "Class"}, {"nodeid": "tests/mcp/test_prompts.py::test_full_prompt_workflow", "type": "Coroutine", "lineno": 263}, {"nodeid": "tests/mcp/test_prompts.py::test_error_handling", "type": "Coroutine", "lineno": 301}]}, {"nodeid": "tests/mcp", "outcome": "passed", "result": [{"nodeid": "tests/mcp/test_prompts.py", "type": "Module"}]}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios", "outcome": "passed", "result": [{"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_1_basic_search", "type": "Function", "lineno": 45}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_2_search_with_no_results", "type": "Function", "lineno": 94}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_3_search_widening", "type": "Function", "lineno": 110}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_4_citation_extraction", "type": "Function", "lineno": 136}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_5_metadata_extraction", "type": "Function", "lineno": 168}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_6_channel_filtering", "type": "Function", "lineno": 204}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_7_youtube_api_search", "type": "Function", "lineno": 236}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_8_fetch_transcript", "type": "Function", "lineno": 264}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_9_search_pagination", "type": "Function", "lineno": 287}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_10_scientific_classification", "type": "Function", "lineno": 319}]}, {"nodeid": "tests/scenarios/test_level0_scenarios.py", "outcome": "passed", "result": [{"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios", "type": "Class"}]}, {"nodeid": "tests/scenarios", "outcome": "passed", "result": [{"nodeid": "tests/scenarios/test_level0_scenarios.py", "type": "Module"}]}, {"nodeid": "tests/test_all_integrations.py", "outcome": "passed", "result": []}, {"nodeid": "tests/test_arangodb_connection.py", "outcome": "passed", "result": [{"nodeid": "tests/test_arangodb_connection.py::test_connection", "type": "Function", "lineno": 31}]}, {"nodeid": "tests/test_integration_summary.py", "outcome": "passed", "result": [{"nodeid": "tests/test_integration_summary.py::test_integration", "type": "Coroutine", "lineno": 18}]}, {"nodeid": "tests/test_minimal.py", "outcome": "passed", "result": [{"nodeid": "tests/test_minimal.py::test_basic", "type": "Function", "lineno": 2}, {"nodeid": "tests/test_minimal.py::test_import_youtube_transcripts", "type": "Function", "lineno": 6}, {"nodeid": "tests/test_minimal.py::test_import_agents", "type": "Function", "lineno": 11}, {"nodeid": "tests/test_minimal.py::test_import_agent_manager", "type": "Function", "lineno": 16}]}, {"nodeid": "tests/test_reporter_verification.py::TestReporterClass", "outcome": "passed", "result": [{"nodeid": "tests/test_reporter_verification.py::TestReporterClass::test_class_method", "type": "Function", "lineno": 37}, {"nodeid": "tests/test_reporter_verification.py::TestReporterClass::test_class_method_with_fixture", "type": "Function", "lineno": 42}]}, {"nodeid": "tests/test_reporter_verification.py", "outcome": "passed", "result": [{"nodeid": "tests/test_reporter_verification.py::test_reporter_basic", "type": "Function", "lineno": 6}, {"nodeid": "tests/test_reporter_verification.py::test_reporter_with_output", "type": "Function", "lineno": 11}, {"nodeid": "tests/test_reporter_verification.py::test_reporter_failure_example", "type": "Function", "lineno": 18}, {"nodeid": "tests/test_reporter_verification.py::test_reporter_with_marker", "type": "Function", "lineno": 26}, {"nodeid": "tests/test_reporter_verification.py::TestReporterClass", "type": "Class"}]}, {"nodeid": "tests/test_search_widening.py::TestSearchWidening", "outcome": "passed", "result": [{"nodeid": "tests/test_search_widening.py::TestSearchWidening::test_exact_match_no_widening", "type": "Function", "lineno": 60}, {"nodeid": "tests/test_search_widening.py::TestSearchWidening::test_synonym_expansion", "type": "Function", "lineno": 71}, {"nodeid": "tests/test_search_widening.py::TestSearchWidening::test_fuzzy_matching", "type": "Function", "lineno": 86}, {"nodeid": "tests/test_search_widening.py::TestSearchWidening::test_no_results_after_widening", "type": "Function", "lineno": 97}, {"nodeid": "tests/test_search_widening.py::TestSearchWidening::test_widening_with_channels", "type": "Function", "lineno": 107}, {"nodeid": "tests/test_search_widening.py::TestSearchWidening::test_semantic_expansion", "type": "Function", "lineno": 120}, {"nodeid": "tests/test_search_widening.py::TestSearchWidening::test_widening_explanation", "type": "Function", "lineno": 141}]}, {"nodeid": "tests/test_search_widening.py", "outcome": "passed", "result": [{"nodeid": "tests/test_search_widening.py::TestSearchWidening", "type": "Class"}]}, {"nodeid": "tests/test_unified_search.py::TestUnifiedSearch", "outcome": "passed", "result": [{"nodeid": "tests/test_unified_search.py::TestUnifiedSearch::test_basic_search_without_optimization", "type": "Function", "lineno": 74}, {"nodeid": "tests/test_unified_search.py::TestUnifiedSearch::test_search_with_optimization", "type": "Function", "lineno": 107}, {"nodeid": "tests/test_unified_search.py::TestUnifiedSearch::test_channel_specific_search", "type": "Function", "lineno": 124}, {"nodeid": "tests/test_unified_search.py::TestUnifiedSearch::test_query_optimizer_directly", "type": "Function", "lineno": 145}, {"nodeid": "tests/test_unified_search.py::TestUnifiedSearch::test_empty_query_handling", "type": "Function", "lineno": 169}, {"nodeid": "tests/test_unified_search.py::TestUnifiedSearch::test_multi_word_search", "type": "Function", "lineno": 183}]}, {"nodeid": "tests/test_unified_search.py", "outcome": "passed", "result": [{"nodeid": "tests/test_unified_search.py::TestUnifiedSearch", "type": "Class"}]}, {"nodeid": "tests", "outcome": "passed", "result": [{"nodeid": "tests/agents", "type": "Package"}, {"nodeid": "tests/cli", "type": "Package"}, {"nodeid": "tests/core", "type": "Package"}, {"nodeid": "tests/integration", "type": "Dir"}, {"nodeid": "tests/level_0", "type": "Package"}, {"nodeid": "tests/mcp", "type": "Package"}, {"nodeid": "tests/scenarios", "type": "Dir"}, {"nodeid": "tests/test_all_integrations.py", "type": "Module"}, {"nodeid": "tests/test_arangodb_connection.py", "type": "Module"}, {"nodeid": "tests/test_integration_summary.py", "type": "Module"}, {"nodeid": "tests/test_minimal.py", "type": "Module"}, {"nodeid": "tests/test_reporter_verification.py", "type": "Module"}, {"nodeid": "tests/test_search_widening.py", "type": "Module"}, {"nodeid": "tests/test_unified_search.py", "type": "Module"}]}], "tests": [{"nodeid": "tests/agents/test_agents.py::TestAgentSystem::test_agent_manager_task_submission", "lineno": 37, "outcome": "passed", "keywords": ["test_agent_manager_task_submission", "asyncio", "pytestmark", "TestAgentSystem", "test_agents.py", "agents", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.008521154057234526, "outcome": "passed"}, "call": {"duration": 0.008729367051273584, "outcome": "passed"}, "teardown": {"duration": 0.00031125592067837715, "outcome": "passed"}}, {"nodeid": "tests/agents/test_agents.py::TestAgentSystem::test_search_optimizer_agent_execution", "lineno": 63, "outcome": "passed", "keywords": ["test_search_optimizer_agent_execution", "asyncio", "pytestmark", "TestAgentSystem", "test_agents.py", "agents", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.007062612101435661, "outcome": "passed"}, "call": {"duration": 0.004973196890205145, "outcome": "passed"}, "teardown": {"duration": 0.00028684595599770546, "outcome": "passed"}}, {"nodeid": "tests/agents/test_agents.py::TestAgentSystem::test_agent_progress_tracking", "lineno": 91, "outcome": "passed", "keywords": ["test_agent_progress_tracking", "asyncio", "pytestmark", "TestAgentSystem", "test_agents.py", "agents", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.006872938014566898, "outcome": "passed"}, "call": {"duration": 0.5039629717357457, "outcome": "passed"}, "teardown": {"duration": 0.00039425771683454514, "outcome": "passed"}}, {"nodeid": "tests/agents/test_agents.py::TestAgentSystem::test_agent_message_passing", "lineno": 112, "outcome": "passed", "keywords": ["test_agent_message_passing", "asyncio", "pytestmark", "TestAgentSystem", "test_agents.py", "agents", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.008061822969466448, "outcome": "passed"}, "call": {"duration": 0.0049659572541713715, "outcome": "passed"}, "teardown": {"duration": 0.0003484082408249378, "outcome": "passed"}}, {"nodeid": "tests/agents/test_agents.py::TestAgentSystem::test_concurrent_agent_execution", "lineno": 145, "outcome": "failed", "keywords": ["test_concurrent_agent_execution", "asyncio", "pytestmark", "TestAgentSystem", "test_agents.py", "agents", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.007142412941902876, "outcome": "passed"}, "call": {"duration": 1.0172973042353988, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/agents/test_agents.py", "lineno": 167, "message": "AssertionError: Expected 3 completed tasks, got 0\nassert 0 == 3"}, "traceback": [{"path": "tests/agents/test_agents.py", "lineno": 167, "message": "in test_concurrent_agent_execution"}], "longrepr": "tests/agents/test_agents.py:167: in test_concurrent_agent_execution\n    assert completed == 3, f\"Expected 3 completed tasks, got {completed}\"\nE   AssertionError: Expected 3 completed tasks, got 0\nE   assert 0 == 3"}, "teardown": {"duration": 0.0006515742279589176, "outcome": "passed"}}, {"nodeid": "tests/agents/test_agents.py::TestAgentSystem::test_agent_error_handling", "lineno": 168, "outcome": "passed", "keywords": ["test_agent_error_handling", "asyncio", "pytestmark", "TestAgentSystem", "test_agents.py", "agents", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.008755438961088657, "outcome": "passed"}, "call": {"duration": 1.0059857317246497, "outcome": "passed"}, "teardown": {"duration": 0.0007603857666254044, "outcome": "passed"}}, {"nodeid": "tests/agents/test_agents.py::TestAgentSystem::test_task_cancellation", "lineno": 187, "outcome": "failed", "keywords": ["test_task_cancellation", "asyncio", "pytestmark", "TestAgentSystem", "test_agents.py", "agents", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.008700036909431219, "outcome": "passed"}, "call": {"duration": 0.10442210594192147, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/agents/test_agents.py", "lineno": 206, "message": "AssertionError: assert 'FAILED' in ['CANCELLED', 'COMPLETED']"}, "traceback": [{"path": "tests/agents/test_agents.py", "lineno": 206, "message": "in test_task_cancellation"}], "longrepr": "tests/agents/test_agents.py:206: in test_task_cancellation\n    assert status[\"status\"] in [\"CANCELLED\", \"COMPLETED\"]  # Might complete before cancel\nE   AssertionError: assert 'FAILED' in ['CANCELLED', 'COMPLETED']"}, "teardown": {"duration": 0.000586432870477438, "outcome": "passed"}}, {"nodeid": "tests/core/test_database.py::TestDatabaseOperations::test_initialize_database_creates_tables", "lineno": 37, "outcome": "passed", "keywords": ["test_initialize_database_creates_tables", "TestDatabaseOperations", "test_database.py", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0033447719179093838, "outcome": "passed"}, "call": {"duration": 0.000532172154635191, "outcome": "passed"}, "teardown": {"duration": 0.0002681249752640724, "outcome": "passed"}}, {"nodeid": "tests/core/test_database.py::TestDatabaseOperations::test_add_transcript_with_real_data", "lineno": 56, "outcome": "passed", "keywords": ["test_add_transcript_with_real_data", "TestDatabaseOperations", "test_database.py", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0025360053405165672, "outcome": "passed"}, "call": {"duration": 0.0029146522283554077, "outcome": "passed"}, "teardown": {"duration": 0.00019550416618585587, "outcome": "passed"}}, {"nodeid": "tests/core/test_database.py::TestDatabaseOperations::test_search_transcripts_with_special_characters", "lineno": 90, "outcome": "passed", "keywords": ["test_search_transcripts_with_special_characters", "TestDatabaseOperations", "test_database.py", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0018248897977173328, "outcome": "passed"}, "call": {"duration": 0.003593076951801777, "outcome": "passed"}, "teardown": {"duration": 0.00014722393825650215, "outcome": "passed"}}, {"nodeid": "tests/core/test_database.py::TestDatabaseOperations::test_search_ranking_with_real_data", "lineno": 128, "outcome": "failed", "keywords": ["test_search_ranking_with_real_data", "TestDatabaseOperations", "test_database.py", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0017964090220630169, "outcome": "passed"}, "call": {"duration": 0.00290860328823328, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/core/test_database.py", "lineno": 157, "message": "AssertionError: Expected at least 2 results, got 1\nassert 1 >= 2\n +  where 1 = len([{'video_id': 'high_relevance', 'title': 'Reinforcement Learning Deep Dive', 'channel_name': 'ML Expert', 'publish_date': '2025-05-01', 'transcript': 'Reinforcement learning is mentioned many times. Reinforcement learning algorithms. Reinforcement learning applications.', 'summary': 'All about reinforcement learning', 'enhanced_transcript': '', 'rank': -3.376822716807368e-06}])"}, "traceback": [{"path": "tests/core/test_database.py", "lineno": 157, "message": "in test_search_ranking_with_real_data"}], "longrepr": "tests/core/test_database.py:157: in test_search_ranking_with_real_data\n    assert len(results) >= 2, f\"Expected at least 2 results, got {len(results)}\"\nE   AssertionError: Expected at least 2 results, got 1\nE   assert 1 >= 2\nE    +  where 1 = len([{'video_id': 'high_relevance', 'title': 'Reinforcement Learning Deep Dive', 'channel_name': 'ML Expert', 'publish_date': '2025-05-01', 'transcript': 'Reinforcement learning is mentioned many times. Reinforcement learning algorithms. Reinforcement learning applications.', 'summary': 'All about reinforcement learning', 'enhanced_transcript': '', 'rank': -3.376822716807368e-06}])"}, "teardown": {"duration": 0.00015719421207904816, "outcome": "passed"}}, {"nodeid": "tests/core/test_database.py::TestDatabaseOperations::test_channel_filtering", "lineno": 170, "outcome": "passed", "keywords": ["test_channel_filtering", "TestDatabaseOperations", "test_database.py", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0018111090175807476, "outcome": "passed"}, "call": {"duration": 0.005604560021311045, "outcome": "passed"}, "teardown": {"duration": 0.00016479380428791046, "outcome": "passed"}}, {"nodeid": "tests/core/test_database.py::TestDatabaseOperations::test_cleanup_old_transcripts", "lineno": 193, "outcome": "passed", "keywords": ["test_cleanup_old_transcripts", "TestDatabaseOperations", "test_database.py", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0019001411274075508, "outcome": "passed"}, "call": {"duration": 0.004488996230065823, "outcome": "passed"}, "teardown": {"duration": 0.00016671326011419296, "outcome": "passed"}}, {"nodeid": "tests/core/test_youtube.py::TestRealYouTube::test_extract_video_id", "lineno": 23, "outcome": "passed", "keywords": ["test_extract_video_id", "TestRealYouTube", "test_youtube.py", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0001131533645093441, "outcome": "passed"}, "call": {"duration": 0.00042413920164108276, "outcome": "passed"}, "teardown": {"duration": 9.709177538752556e-05, "outcome": "passed"}}, {"nodeid": "tests/core/test_youtube.py::TestRealYouTube::test_fetch_real_transcript", "lineno": 37, "outcome": "skipped", "keywords": ["test_fetch_real_transcript", "slow", "pytestmark", "TestRealYouTube", "test_youtube.py", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00010484177619218826, "outcome": "passed"}, "call": {"duration": 1.3303848588839173, "outcome": "skipped", "stdout": "Error fetching transcript for jNQXAC9IVRw: no element found: line 1, column 0\n", "longrepr": "('/home/graham/workspace/experiments/youtube_transcripts/tests/core/test_youtube.py', 48, 'Skipped: Transcript not available for test video')"}, "teardown": {"duration": 0.00010864203795790672, "outcome": "passed"}}, {"nodeid": "tests/core/test_youtube.py::TestRealYouTube::test_get_channel_videos_real", "lineno": 54, "outcome": "passed", "keywords": ["test_get_channel_videos_real", "slow", "pytestmark", "TestRealYouTube", "test_youtube.py", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00010884227231144905, "outcome": "passed"}, "call": {"duration": 9.808279001154006, "outcome": "passed", "stdout": "\nFetched 3 videos from channel\nFirst video: YouTube - Videos\n"}, "teardown": {"duration": 0.00013086199760437012, "outcome": "passed"}}, {"nodeid": "tests/core/test_youtube.py::TestRealYouTube::test_process_channels_with_empty_list", "lineno": 78, "outcome": "passed", "keywords": ["test_process_channels_with_empty_list", "TestRealYouTube", "test_youtube.py", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00013020215556025505, "outcome": "passed"}, "call": {"duration": 0.0001140921376645565, "outcome": "passed"}, "teardown": {"duration": 9.368220344185829e-05, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestScientificPipeline::test_pipeline_initialization", "lineno": 23, "outcome": "passed", "keywords": ["test_pipeline_initialization", "TestScientificPipeline", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00033765705302357674, "outcome": "passed"}, "call": {"duration": 5.505233658943325, "outcome": "passed", "stdout": "Downloading en_core_web_sm...\nCollecting en-core-web-sm==3.8.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12.8/12.8 MB 36.9 MB/s eta 0:00:00\nInstalling collected packages: en-core-web-sm\nSuccessfully installed en-core-web-sm-3.8.0\n\u001b[38;5;2m\u2714 Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n"}, "teardown": {"duration": 0.00012263329699635506, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestScientificPipeline::test_citation_detection", "lineno": 31, "outcome": "passed", "keywords": ["test_citation_detection", "TestScientificPipeline", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0001218533143401146, "outcome": "passed"}, "call": {"duration": 0.5292121930979192, "outcome": "passed"}, "teardown": {"duration": 0.00011650193482637405, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestScientificPipeline::test_institution_recognition", "lineno": 48, "outcome": "passed", "keywords": ["test_institution_recognition", "TestScientificPipeline", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00011908169835805893, "outcome": "passed"}, "call": {"duration": 0.3282071389257908, "outcome": "passed"}, "teardown": {"duration": 0.00011076219379901886, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestScientificPipeline::test_technical_term_extraction", "lineno": 62, "outcome": "passed", "keywords": ["test_technical_term_extraction", "TestScientificPipeline", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00011973222717642784, "outcome": "passed"}, "call": {"duration": 0.32657785527408123, "outcome": "passed"}, "teardown": {"duration": 0.00012012198567390442, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestScientificPipeline::test_speaker_extraction_in_pipeline", "lineno": 79, "outcome": "passed", "keywords": ["test_speaker_extraction_in_pipeline", "TestScientificPipeline", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00011243205517530441, "outcome": "passed"}, "call": {"duration": 0.3325763843022287, "outcome": "passed"}, "teardown": {"duration": 0.00012552272528409958, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestCitationDetector::test_arxiv_detection", "lineno": 97, "outcome": "passed", "keywords": ["test_arxiv_detection", "TestCitationDetector", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00011943187564611435, "outcome": "passed"}, "call": {"duration": 0.32505816174671054, "outcome": "passed"}, "teardown": {"duration": 0.00014397315680980682, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestCitationDetector::test_doi_detection", "lineno": 113, "outcome": "passed", "keywords": ["test_doi_detection", "TestCitationDetector", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00014079315587878227, "outcome": "passed"}, "call": {"duration": 0.32298162719234824, "outcome": "passed"}, "teardown": {"duration": 0.0001275031827390194, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestCitationDetector::test_author_year_detection", "lineno": 128, "outcome": "failed", "keywords": ["test_author_year_detection", "TestCitationDetector", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00012736208736896515, "outcome": "passed"}, "call": {"duration": 0.3275566245429218, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/core/utils/test_scientific_extractors.py", "lineno": 139, "message": "AssertionError: assert 1 >= 4\n +  where 1 = len([Citation(type='author_year', text='Smith and Jones (2022)', id=None, authors='Smith and Jones', year='2022', title=None, context='(2017) and Devlin et al., 2019. \\n        See also Smith and Jones (2022) and the work by Liu et al. 2023.', confidence=1.0, position=(77, 99))])"}, "traceback": [{"path": "tests/core/utils/test_scientific_extractors.py", "lineno": 139, "message": "in test_author_year_detection"}], "longrepr": "tests/core/utils/test_scientific_extractors.py:139: in test_author_year_detection\n    assert len(author_citations) >= 4\nE   AssertionError: assert 1 >= 4\nE    +  where 1 = len([Citation(type='author_year', text='Smith and Jones (2022)', id=None, authors='Smith and Jones', year='2022', title=None, context='(2017) and Devlin et al., 2019. \\n        See also Smith and Jones (2022) and the work by Liu et al. 2023.', confidence=1.0, position=(77, 99))])"}, "teardown": {"duration": 0.0001374729909002781, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestCitationDetector::test_citation_formatting", "lineno": 144, "outcome": "passed", "keywords": ["test_citation_formatting", "TestCitationDetector", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0001359027810394764, "outcome": "passed"}, "call": {"duration": 0.3264648620970547, "outcome": "passed"}, "teardown": {"duration": 0.0001422329805791378, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestSpeakerExtractor::test_introduction_extraction", "lineno": 176, "outcome": "passed", "keywords": ["test_introduction_extraction", "TestSpeakerExtractor", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00013555306941270828, "outcome": "passed"}, "call": {"duration": 0.3308065952733159, "outcome": "passed"}, "teardown": {"duration": 0.00013299286365509033, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestSpeakerExtractor::test_labeled_speaker_extraction", "lineno": 195, "outcome": "failed", "keywords": ["test_labeled_speaker_extraction", "TestSpeakerExtractor", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00013752281665802002, "outcome": "passed"}, "call": {"duration": 0.3302547740750015, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/core/utils/test_scientific_extractors.py", "lineno": 216, "message": "assert False\n +  where False = any(<generator object TestSpeakerExtractor.test_labeled_speaker_extraction.<locals>.<genexpr> at 0x76f824de0c70>)"}, "traceback": [{"path": "tests/core/utils/test_scientific_extractors.py", "lineno": 216, "message": "in test_labeled_speaker_extraction"}], "longrepr": "tests/core/utils/test_scientific_extractors.py:216: in test_labeled_speaker_extraction\n    assert any('Dr.' in t for t in titles)\nE   assert False\nE    +  where False = any(<generator object TestSpeakerExtractor.test_labeled_speaker_extraction.<locals>.<genexpr> at 0x76f824de0c70>)"}, "teardown": {"duration": 0.00014060316607356071, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestSpeakerExtractor::test_speaker_deduplication", "lineno": 217, "outcome": "passed", "keywords": ["test_speaker_deduplication", "TestSpeakerExtractor", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00012496300041675568, "outcome": "passed"}, "call": {"duration": 0.3261514948680997, "outcome": "passed"}, "teardown": {"duration": 0.00013331277295947075, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestSpeakerExtractor::test_speaker_formatting", "lineno": 231, "outcome": "passed", "keywords": ["test_speaker_formatting", "TestSpeakerExtractor", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00013048294931650162, "outcome": "passed"}, "call": {"duration": 0.315158988814801, "outcome": "passed"}, "teardown": {"duration": 0.0001440928317606449, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestContentClassifier::test_content_type_classification", "lineno": 258, "outcome": "passed", "keywords": ["test_content_type_classification", "TestContentClassifier", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00013215281069278717, "outcome": "passed"}, "call": {"duration": 0.00499437702819705, "outcome": "passed"}, "teardown": {"duration": 9.858189150691032e-05, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestContentClassifier::test_academic_level_classification", "lineno": 291, "outcome": "passed", "keywords": ["test_academic_level_classification", "TestContentClassifier", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00011438177898526192, "outcome": "passed"}, "call": {"duration": 0.003591547254472971, "outcome": "passed"}, "teardown": {"duration": 9.493203833699226e-05, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestContentClassifier::test_topic_extraction", "lineno": 324, "outcome": "passed", "keywords": ["test_topic_extraction", "TestContentClassifier", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0001186230219900608, "outcome": "passed"}, "call": {"duration": 0.0019890028052031994, "outcome": "passed"}, "teardown": {"duration": 9.914301335811615e-05, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestContentClassifier::test_quality_indicators", "lineno": 343, "outcome": "failed", "keywords": ["test_quality_indicators", "TestContentClassifier", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00011040177196264267, "outcome": "passed"}, "call": {"duration": 0.00497615709900856, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/core/utils/test_scientific_extractors.py", "lineno": 366, "message": "assert 0.4666666666666667 > 0.5"}, "traceback": [{"path": "tests/core/utils/test_scientific_extractors.py", "lineno": 366, "message": "in test_quality_indicators"}], "longrepr": "tests/core/utils/test_scientific_extractors.py:366: in test_quality_indicators\n    assert indicators['academic_language'] > 0.5\nE   assert 0.4666666666666667 > 0.5"}, "teardown": {"duration": 0.00010827230289578438, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestMetadataExtractor::test_full_extraction", "lineno": 373, "outcome": "passed", "keywords": ["test_full_extraction", "TestMetadataExtractor", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00011949194595217705, "outcome": "passed"}, "call": {"duration": 0.6211300790309906, "outcome": "passed"}, "teardown": {"duration": 0.00013003312051296234, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestMetadataExtractor::test_batch_extraction", "lineno": 410, "outcome": "passed", "keywords": ["test_batch_extraction", "TestMetadataExtractor", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00012751296162605286, "outcome": "passed"}, "call": {"duration": 0.323608071077615, "outcome": "passed"}, "teardown": {"duration": 0.0001257532276213169, "outcome": "passed"}}, {"nodeid": "tests/core/utils/test_scientific_extractors.py::TestIntegration::test_end_to_end_extraction", "lineno": 437, "outcome": "failed", "keywords": ["test_end_to_end_extraction", "TestIntegration", "test_scientific_extractors.py", "utils", "core", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.000127352774143219, "outcome": "passed"}, "call": {"duration": 0.3425707486458123, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/core/utils/test_scientific_extractors.py", "lineno": 474, "message": "AssertionError: assert 'Stanford' in ['NLP', 'BERT', 'MIT', 'GPT']"}, "traceback": [{"path": "tests/core/utils/test_scientific_extractors.py", "lineno": 474, "message": "in test_end_to_end_extraction"}], "longrepr": "tests/core/utils/test_scientific_extractors.py:474: in test_end_to_end_extraction\n    assert 'Stanford' in metadata['institutions']\nE   AssertionError: assert 'Stanford' in ['NLP', 'BERT', 'MIT', 'GPT']"}, "teardown": {"duration": 0.00014367280527949333, "outcome": "passed"}}, {"nodeid": "tests/integration/test_arangodb_features.py::TestArangoDBIntegration::test_store_and_retrieve_with_embeddings", "lineno": 170, "outcome": "skipped", "keywords": ["test_store_and_retrieve_with_embeddings", "asyncio", "pytestmark", "TestArangoDBIntegration", "skipif", "test_arangodb_features.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00011816341429948807, "outcome": "skipped", "longrepr": "('/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_arangodb_features.py', 171, 'Skipped: ArangoDB utilities not available')"}, "teardown": {"duration": 0.00010537216439843178, "outcome": "passed"}}, {"nodeid": "tests/integration/test_arangodb_features.py::TestArangoDBIntegration::test_hybrid_search", "lineno": 190, "outcome": "skipped", "keywords": ["test_hybrid_search", "asyncio", "pytestmark", "TestArangoDBIntegration", "skipif", "test_arangodb_features.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0001061619259417057, "outcome": "skipped", "longrepr": "('/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_arangodb_features.py', 191, 'Skipped: ArangoDB utilities not available')"}, "teardown": {"duration": 8.962210267782211e-05, "outcome": "passed"}}, {"nodeid": "tests/integration/test_arangodb_features.py::TestArangoDBIntegration::test_citation_network", "lineno": 209, "outcome": "skipped", "keywords": ["test_citation_network", "asyncio", "pytestmark", "TestArangoDBIntegration", "skipif", "test_arangodb_features.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.781168773770332e-05, "outcome": "skipped", "longrepr": "('/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_arangodb_features.py', 210, 'Skipped: ArangoDB utilities not available')"}, "teardown": {"duration": 0.00010146293789148331, "outcome": "passed"}}, {"nodeid": "tests/integration/test_arangodb_features.py::TestArangoDBIntegration::test_speaker_relationships", "lineno": 229, "outcome": "skipped", "keywords": ["test_speaker_relationships", "asyncio", "pytestmark", "TestArangoDBIntegration", "skipif", "test_arangodb_features.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00010224198922514915, "outcome": "skipped", "longrepr": "('/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_arangodb_features.py', 230, 'Skipped: ArangoDB utilities not available')"}, "teardown": {"duration": 8.890219032764435e-05, "outcome": "passed"}}, {"nodeid": "tests/integration/test_arangodb_features.py::TestArangoDBIntegration::test_entity_linking", "lineno": 264, "outcome": "skipped", "keywords": ["test_entity_linking", "asyncio", "pytestmark", "TestArangoDBIntegration", "skipif", "test_arangodb_features.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.758211672306061e-05, "outcome": "skipped", "longrepr": "('/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_arangodb_features.py', 265, 'Skipped: ArangoDB utilities not available')"}, "teardown": {"duration": 9.993230924010277e-05, "outcome": "passed"}}, {"nodeid": "tests/integration/test_arangodb_features.py::TestArangoDBIntegration::test_find_related_videos", "lineno": 302, "outcome": "skipped", "keywords": ["test_find_related_videos", "asyncio", "pytestmark", "TestArangoDBIntegration", "skipif", "test_arangodb_features.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00010089203715324402, "outcome": "skipped", "longrepr": "('/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_arangodb_features.py', 303, 'Skipped: ArangoDB utilities not available')"}, "teardown": {"duration": 0.0001917337067425251, "outcome": "passed"}}, {"nodeid": "tests/integration/test_arangodb_features.py::TestArangoDBIntegration::test_research_analyzer_integration", "lineno": 320, "outcome": "skipped", "keywords": ["test_research_analyzer_integration", "asyncio", "pytestmark", "TestArangoDBIntegration", "skipif", "test_arangodb_features.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.833183139562607e-05, "outcome": "skipped", "longrepr": "('/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_arangodb_features.py', 321, 'Skipped: ArangoDB utilities not available')"}, "teardown": {"duration": 9.458186104893684e-05, "outcome": "passed"}}, {"nodeid": "tests/integration/test_arxiv_youtube_integration.py::TestArxivYouTubeIntegration::test_citation_validation_pipeline", "lineno": 86, "outcome": "failed", "keywords": ["test_citation_validation_pipeline", "asyncio", "pytestmark", "TestArxivYouTubeIntegration", "test_arxiv_youtube_integration.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.31912950379773974, "outcome": "passed", "log": [{"name": "youtube_transcripts.deepretrieval_optimizer", "msg": "Could not load LoRA adapter: No module named 'unsloth'", "args": null, "levelname": "WARNING", "levelno": 30, "pathname": "/home/graham/workspace/experiments/youtube_transcripts/src/youtube_transcripts/deepretrieval_optimizer.py", "filename": "deepretrieval_optimizer.py", "module": "deepretrieval_optimizer", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 67, "funcName": "_load_lora_adapter", "created": 1749141890.0964613, "msecs": 96.0, "relativeCreated": 31483.94012451172, "thread": 130816157991232, "threadName": "MainThread", "processName": "MainProcess", "process": 369085, "taskName": null}]}, "call": {"duration": 7.035059372894466, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_arxiv_youtube_integration.py", "lineno": 100, "message": "AssertionError: assert 'paper' == 'arxiv'\n  \n  - arxiv\n  + paper"}, "traceback": [{"path": "tests/integration/test_arxiv_youtube_integration.py", "lineno": 100, "message": "in test_citation_validation_pipeline"}], "longrepr": "tests/integration/test_arxiv_youtube_integration.py:100: in test_citation_validation_pipeline\n    assert citations[0].type == \"arxiv\"\nE   AssertionError: assert 'paper' == 'arxiv'\nE     \nE     - arxiv\nE     + paper"}, "teardown": {"duration": 0.00031915586441755295, "outcome": "passed"}}, {"nodeid": "tests/integration/test_arxiv_youtube_integration.py::TestArxivYouTubeIntegration::test_research_enhancement_pipeline", "lineno": 113, "outcome": "failed", "keywords": ["test_research_enhancement_pipeline", "asyncio", "pytestmark", "TestArxivYouTubeIntegration", "test_arxiv_youtube_integration.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.3299896167591214, "outcome": "passed", "log": [{"name": "youtube_transcripts.deepretrieval_optimizer", "msg": "Could not load LoRA adapter: No module named 'unsloth'", "args": null, "levelname": "WARNING", "levelno": 30, "pathname": "/home/graham/workspace/experiments/youtube_transcripts/src/youtube_transcripts/deepretrieval_optimizer.py", "filename": "deepretrieval_optimizer.py", "module": "deepretrieval_optimizer", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 67, "funcName": "_load_lora_adapter", "created": 1749141897.4982984, "msecs": 498.0, "relativeCreated": 38885.77723503113, "thread": 130816157991232, "threadName": "MainThread", "processName": "MainProcess", "process": 369085, "taskName": null}]}, "call": {"duration": 0.00023699505254626274, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_arxiv_youtube_integration.py", "lineno": 124, "message": "AttributeError: 'MetadataExtractor' object has no attribute 'extract_entities'"}, "traceback": [{"path": "tests/integration/test_arxiv_youtube_integration.py", "lineno": 124, "message": "in test_research_enhancement_pipeline"}], "longrepr": "tests/integration/test_arxiv_youtube_integration.py:124: in test_research_enhancement_pipeline\n    metadata = metadata_extractor.extract_entities(transcript)\nE   AttributeError: 'MetadataExtractor' object has no attribute 'extract_entities'"}, "teardown": {"duration": 0.00028339633718132973, "outcome": "passed"}}, {"nodeid": "tests/integration/test_arxiv_youtube_integration.py::TestArxivYouTubeIntegration::test_cross_reference_search", "lineno": 142, "outcome": "failed", "keywords": ["test_cross_reference_search", "TestArxivYouTubeIntegration", "test_arxiv_youtube_integration.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.02290044305846095, "outcome": "passed", "log": [{"name": "youtube_transcripts.deepretrieval_optimizer", "msg": "Could not load LoRA adapter: No module named 'unsloth'", "args": null, "levelname": "WARNING", "levelno": 30, "pathname": "/home/graham/workspace/experiments/youtube_transcripts/src/youtube_transcripts/deepretrieval_optimizer.py", "filename": "deepretrieval_optimizer.py", "module": "deepretrieval_optimizer", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 67, "funcName": "_load_lora_adapter", "created": 1749141897.8355181, "msecs": 835.0, "relativeCreated": 39222.996950149536, "thread": 130816157991232, "threadName": "MainThread", "processName": "MainProcess", "process": 369085, "taskName": null}]}, "call": {"duration": 0.0001360829919576645, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_arxiv_youtube_integration.py", "lineno": 150, "message": "TypeError: UnifiedYouTubeSearch.search() got an unexpected keyword argument 'use_widening'"}, "traceback": [{"path": "tests/integration/test_arxiv_youtube_integration.py", "lineno": 150, "message": "in test_cross_reference_search"}], "longrepr": "tests/integration/test_arxiv_youtube_integration.py:150: in test_cross_reference_search\n    results = youtube_client.search(\nE   TypeError: UnifiedYouTubeSearch.search() got an unexpected keyword argument 'use_widening'"}, "teardown": {"duration": 0.00011423183605074883, "outcome": "passed"}}, {"nodeid": "tests/integration/test_arxiv_youtube_integration.py::TestArxivYouTubeIntegration::test_evidence_based_validation", "lineno": 162, "outcome": "passed", "keywords": ["test_evidence_based_validation", "asyncio", "pytestmark", "TestArxivYouTubeIntegration", "test_arxiv_youtube_integration.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.3072311179712415, "outcome": "passed"}, "call": {"duration": 0.00021933484822511673, "outcome": "passed"}, "teardown": {"duration": 0.00020157406106591225, "outcome": "passed"}}, {"nodeid": "tests/integration/test_arxiv_youtube_integration.py::TestArxivYouTubeIntegration::test_unified_metadata_extraction", "lineno": 201, "outcome": "failed", "keywords": ["test_unified_metadata_extraction", "TestArxivYouTubeIntegration", "test_arxiv_youtube_integration.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.30787802208215, "outcome": "passed"}, "call": {"duration": 0.0001710541546344757, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_arxiv_youtube_integration.py", "lineno": 212, "message": "AttributeError: 'MetadataExtractor' object has no attribute 'extract_entities'"}, "traceback": [{"path": "tests/integration/test_arxiv_youtube_integration.py", "lineno": 212, "message": "in test_unified_metadata_extraction"}], "longrepr": "tests/integration/test_arxiv_youtube_integration.py:212: in test_unified_metadata_extraction\n    metadata = metadata_extractor.extract_entities(transcript)\nE   AttributeError: 'MetadataExtractor' object has no attribute 'extract_entities'"}, "teardown": {"duration": 0.0001302529126405716, "outcome": "passed"}}, {"nodeid": "tests/integration/test_arxiv_youtube_integration.py::TestArxivYouTubeIntegration::test_research_discovery_workflow", "lineno": 230, "outcome": "failed", "keywords": ["test_research_discovery_workflow", "asyncio", "pytestmark", "TestArxivYouTubeIntegration", "test_arxiv_youtube_integration.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.02237327117472887, "outcome": "passed", "log": [{"name": "youtube_transcripts.deepretrieval_optimizer", "msg": "Could not load LoRA adapter: No module named 'unsloth'", "args": null, "levelname": "WARNING", "levelno": 30, "pathname": "/home/graham/workspace/experiments/youtube_transcripts/src/youtube_transcripts/deepretrieval_optimizer.py", "filename": "deepretrieval_optimizer.py", "module": "deepretrieval_optimizer", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 67, "funcName": "_load_lora_adapter", "created": 1749141898.4829993, "msecs": 482.0, "relativeCreated": 39870.47815322876, "thread": 130816157991232, "threadName": "MainThread", "processName": "MainProcess", "process": 369085, "taskName": null}]}, "call": {"duration": 4.904482752084732, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/src/youtube_transcripts/unified_search.py", "lineno": 150, "message": "AttributeError: 'SearchWidener' object has no attribute 'widen_search'"}, "traceback": [{"path": "tests/integration/test_arxiv_youtube_integration.py", "lineno": 240, "message": "in test_research_discovery_workflow"}, {"path": "src/youtube_transcripts/unified_search.py", "lineno": 150, "message": "in search"}], "longrepr": "tests/integration/test_arxiv_youtube_integration.py:240: in test_research_discovery_workflow\n    video_results = youtube_client.search(topic, limit=5)\nsrc/youtube_transcripts/unified_search.py:150: in search\n    widened = self.search_widener.widen_search(search_query)\nE   AttributeError: 'SearchWidener' object has no attribute 'widen_search'"}, "teardown": {"duration": 0.00027051568031311035, "outcome": "passed"}}, {"nodeid": "tests/integration/test_database_adapter.py::TestSQLiteBackend::test_sqlite_initialization", "lineno": 123, "outcome": "error", "keywords": ["test_sqlite_initialization", "asyncio", "pytestmark", "TestSQLiteBackend", "test_database_adapter.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00031771697103977203, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_database_adapter.py", "lineno": 82, "message": "NameError: name 'TestReport' is not defined"}, "traceback": [{"path": "tests/integration/test_database_adapter.py", "lineno": 82, "message": "in test_report"}], "longrepr": "tests/integration/test_database_adapter.py:82: in test_report\n    return TestReport()\nE   NameError: name 'TestReport' is not defined"}, "teardown": {"duration": 0.00017263414338231087, "outcome": "passed"}}, {"nodeid": "tests/integration/test_database_adapter.py::TestSQLiteBackend::test_sqlite_store_and_retrieve", "lineno": 161, "outcome": "error", "keywords": ["test_sqlite_store_and_retrieve", "asyncio", "pytestmark", "TestSQLiteBackend", "test_database_adapter.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.000276125967502594, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_database_adapter.py", "lineno": 82, "message": "NameError: name 'TestReport' is not defined"}, "traceback": [{"path": "tests/integration/test_database_adapter.py", "lineno": 82, "message": "in test_report"}], "longrepr": "tests/integration/test_database_adapter.py:82: in test_report\n    return TestReport()\nE   NameError: name 'TestReport' is not defined"}, "teardown": {"duration": 0.00016026291996240616, "outcome": "passed"}}, {"nodeid": "tests/integration/test_database_adapter.py::TestSQLiteBackend::test_sqlite_search", "lineno": 199, "outcome": "error", "keywords": ["test_sqlite_search", "asyncio", "pytestmark", "TestSQLiteBackend", "test_database_adapter.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00027747591957449913, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_database_adapter.py", "lineno": 82, "message": "NameError: name 'TestReport' is not defined"}, "traceback": [{"path": "tests/integration/test_database_adapter.py", "lineno": 82, "message": "in test_report"}], "longrepr": "tests/integration/test_database_adapter.py:82: in test_report\n    return TestReport()\nE   NameError: name 'TestReport' is not defined"}, "teardown": {"duration": 0.0001623528078198433, "outcome": "passed"}}, {"nodeid": "tests/integration/test_database_adapter.py::TestSQLiteBackend::test_sqlite_evidence_finding", "lineno": 237, "outcome": "error", "keywords": ["test_sqlite_evidence_finding", "asyncio", "pytestmark", "TestSQLiteBackend", "test_database_adapter.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00026886630803346634, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_database_adapter.py", "lineno": 82, "message": "NameError: name 'TestReport' is not defined"}, "traceback": [{"path": "tests/integration/test_database_adapter.py", "lineno": 82, "message": "in test_report"}], "longrepr": "tests/integration/test_database_adapter.py:82: in test_report\n    return TestReport()\nE   NameError: name 'TestReport' is not defined"}, "teardown": {"duration": 0.00016272300854325294, "outcome": "passed"}}, {"nodeid": "tests/integration/test_database_adapter.py::TestDatabaseAdapter::test_auto_detection", "lineno": 271, "outcome": "error", "keywords": ["test_auto_detection", "asyncio", "pytestmark", "TestDatabaseAdapter", "test_database_adapter.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0002428959123790264, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_database_adapter.py", "lineno": 82, "message": "NameError: name 'TestReport' is not defined"}, "traceback": [{"path": "tests/integration/test_database_adapter.py", "lineno": 82, "message": "in test_report"}], "longrepr": "tests/integration/test_database_adapter.py:82: in test_report\n    return TestReport()\nE   NameError: name 'TestReport' is not defined"}, "teardown": {"duration": 0.00015236437320709229, "outcome": "passed"}}, {"nodeid": "tests/integration/test_database_adapter.py::TestDatabaseAdapter::test_forced_backends", "lineno": 296, "outcome": "error", "keywords": ["test_forced_backends", "asyncio", "pytestmark", "TestDatabaseAdapter", "test_database_adapter.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00025010621175169945, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_database_adapter.py", "lineno": 82, "message": "NameError: name 'TestReport' is not defined"}, "traceback": [{"path": "tests/integration/test_database_adapter.py", "lineno": 82, "message": "in test_report"}], "longrepr": "tests/integration/test_database_adapter.py:82: in test_report\n    return TestReport()\nE   NameError: name 'TestReport' is not defined"}, "teardown": {"duration": 0.000153333880007267, "outcome": "passed"}}, {"nodeid": "tests/integration/test_database_adapter.py::TestDatabaseAdapter::test_adapter_interface", "lineno": 329, "outcome": "error", "keywords": ["test_adapter_interface", "asyncio", "pytestmark", "TestDatabaseAdapter", "test_database_adapter.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0002643158659338951, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_database_adapter.py", "lineno": 82, "message": "NameError: name 'TestReport' is not defined"}, "traceback": [{"path": "tests/integration/test_database_adapter.py", "lineno": 82, "message": "in test_report"}], "longrepr": "tests/integration/test_database_adapter.py:82: in test_report\n    return TestReport()\nE   NameError: name 'TestReport' is not defined"}, "teardown": {"duration": 0.0001614629290997982, "outcome": "passed"}}, {"nodeid": "tests/integration/test_database_adapter.py::TestDatabaseConfig::test_config_from_env", "lineno": 372, "outcome": "error", "keywords": ["test_config_from_env", "TestDatabaseConfig", "test_database_adapter.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00015997420996427536, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_database_adapter.py", "lineno": 82, "message": "NameError: name 'TestReport' is not defined"}, "traceback": [{"path": "tests/integration/test_database_adapter.py", "lineno": 82, "message": "in test_report"}], "longrepr": "tests/integration/test_database_adapter.py:82: in test_report\n    return TestReport()\nE   NameError: name 'TestReport' is not defined"}, "teardown": {"duration": 0.00010882224887609482, "outcome": "passed"}}, {"nodeid": "tests/integration/test_database_adapter.py::TestDatabaseConfig::test_backend_config_generation", "lineno": 405, "outcome": "error", "keywords": ["test_backend_config_generation", "TestDatabaseConfig", "test_database_adapter.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00014278292655944824, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_database_adapter.py", "lineno": 82, "message": "NameError: name 'TestReport' is not defined"}, "traceback": [{"path": "tests/integration/test_database_adapter.py", "lineno": 82, "message": "in test_report"}], "longrepr": "tests/integration/test_database_adapter.py:82: in test_report\n    return TestReport()\nE   NameError: name 'TestReport' is not defined"}, "teardown": {"duration": 0.00012182304635643959, "outcome": "passed"}}, {"nodeid": "tests/integration/test_database_adapter.py::test_full_integration_flow", "lineno": 430, "outcome": "error", "keywords": ["test_full_integration_flow", "asyncio", "pytestmark", "test_database_adapter.py", "integration", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.000276095699518919, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_database_adapter.py", "lineno": 82, "message": "NameError: name 'TestReport' is not defined"}, "traceback": [{"path": "tests/integration/test_database_adapter.py", "lineno": 82, "message": "in test_report"}], "longrepr": "tests/integration/test_database_adapter.py:82: in test_report\n    return TestReport()\nE   NameError: name 'TestReport' is not defined"}, "teardown": {"duration": 0.0001623239368200302, "outcome": "passed"}}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_module_attributes", "lineno": 30, "outcome": "passed", "keywords": ["test_module_attributes", "asyncio", "pytestmark", "TestYoutubeTranscriptsStandardized", "test_youtube_transcripts_standardized.py", "level_0", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0007468760013580322, "outcome": "passed", "stderr": "2025-06-05 12:45:03.454 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:start:50 - youtube_transcripts module started successfully\n"}, "call": {"duration": 0.00014781299978494644, "outcome": "passed"}, "teardown": {"duration": 0.00024705473333597183, "outcome": "passed", "stderr": "2025-06-05 12:45:03.454 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:stop:58 - youtube_transcripts module stopped\n"}}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_standardized_response_format", "lineno": 45, "outcome": "passed", "keywords": ["test_standardized_response_format", "asyncio", "pytestmark", "TestYoutubeTranscriptsStandardized", "test_youtube_transcripts_standardized.py", "level_0", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0003968081437051296, "outcome": "passed", "stderr": "2025-06-05 12:45:03.455 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:start:50 - youtube_transcripts module started successfully\n"}, "call": {"duration": 0.00014135288074612617, "outcome": "passed"}, "teardown": {"duration": 0.00023509515449404716, "outcome": "passed", "stderr": "2025-06-05 12:45:03.455 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:stop:58 - youtube_transcripts module stopped\n"}}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_error_response_format", "lineno": 71, "outcome": "passed", "keywords": ["test_error_response_format", "asyncio", "pytestmark", "TestYoutubeTranscriptsStandardized", "test_youtube_transcripts_standardized.py", "level_0", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0003806278109550476, "outcome": "passed", "stderr": "2025-06-05 12:45:03.456 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:start:50 - youtube_transcripts module started successfully\n"}, "call": {"duration": 0.00013461289927363396, "outcome": "passed"}, "teardown": {"duration": 0.00023294473066926003, "outcome": "passed", "stderr": "2025-06-05 12:45:03.456 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:stop:58 - youtube_transcripts module stopped\n"}}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_fetch_transcript_missing_params", "lineno": 91, "outcome": "passed", "keywords": ["test_fetch_transcript_missing_params", "asyncio", "pytestmark", "TestYoutubeTranscriptsStandardized", "test_youtube_transcripts_standardized.py", "level_0", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0003765178844332695, "outcome": "passed", "stderr": "2025-06-05 12:45:03.457 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:start:50 - youtube_transcripts module started successfully\n"}, "call": {"duration": 0.00019480474293231964, "outcome": "passed", "stderr": "2025-06-05 12:45:03.457 | ERROR    | youtube_transcripts.integrations.youtube_transcripts_module:process:83 - Error in youtube_transcripts: video_id is required\n"}, "teardown": {"duration": 0.0002414151094853878, "outcome": "passed", "stderr": "2025-06-05 12:45:03.457 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:stop:58 - youtube_transcripts module stopped\n"}}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_search_transcripts", "lineno": 105, "outcome": "passed", "keywords": ["test_search_transcripts", "asyncio", "pytestmark", "TestYoutubeTranscriptsStandardized", "test_youtube_transcripts_standardized.py", "level_0", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00037788785994052887, "outcome": "passed", "stderr": "2025-06-05 12:45:03.458 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:start:50 - youtube_transcripts module started successfully\n"}, "call": {"duration": 0.00013805273920297623, "outcome": "passed"}, "teardown": {"duration": 0.00023530470207333565, "outcome": "passed", "stderr": "2025-06-05 12:45:03.458 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:stop:58 - youtube_transcripts module stopped\n"}}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_get_channel_videos", "lineno": 126, "outcome": "passed", "keywords": ["test_get_channel_videos", "asyncio", "pytestmark", "TestYoutubeTranscriptsStandardized", "test_youtube_transcripts_standardized.py", "level_0", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0003681075759232044, "outcome": "passed", "stderr": "2025-06-05 12:45:03.459 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:start:50 - youtube_transcripts module started successfully\n"}, "call": {"duration": 0.00013731280341744423, "outcome": "passed"}, "teardown": {"duration": 0.0002400549128651619, "outcome": "passed", "stderr": "2025-06-05 12:45:03.459 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:stop:58 - youtube_transcripts module stopped\n"}}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_extract_keywords_with_transcript", "lineno": 145, "outcome": "passed", "keywords": ["test_extract_keywords_with_transcript", "asyncio", "pytestmark", "TestYoutubeTranscriptsStandardized", "test_youtube_transcripts_standardized.py", "level_0", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0003724279813468456, "outcome": "passed", "stderr": "2025-06-05 12:45:03.460 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:start:50 - youtube_transcripts module started successfully\n"}, "call": {"duration": 0.00013653328642249107, "outcome": "passed"}, "teardown": {"duration": 0.00023362506181001663, "outcome": "passed", "stderr": "2025-06-05 12:45:03.460 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:stop:58 - youtube_transcripts module stopped\n"}}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_extract_keywords_with_video_id", "lineno": 164, "outcome": "passed", "keywords": ["test_extract_keywords_with_video_id", "asyncio", "pytestmark", "TestYoutubeTranscriptsStandardized", "test_youtube_transcripts_standardized.py", "level_0", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00036646798253059387, "outcome": "passed", "stderr": "2025-06-05 12:45:03.461 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:start:50 - youtube_transcripts module started successfully\n"}, "call": {"duration": 0.00013423291966319084, "outcome": "passed"}, "teardown": {"duration": 0.00023096520453691483, "outcome": "passed", "stderr": "2025-06-05 12:45:03.461 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:stop:58 - youtube_transcripts module stopped\n"}}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_summarize_video_with_id", "lineno": 180, "outcome": "passed", "keywords": ["test_summarize_video_with_id", "asyncio", "pytestmark", "TestYoutubeTranscriptsStandardized", "test_youtube_transcripts_standardized.py", "level_0", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0003711879253387451, "outcome": "passed", "stderr": "2025-06-05 12:45:03.462 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:start:50 - youtube_transcripts module started successfully\n"}, "call": {"duration": 0.00014281272888183594, "outcome": "passed"}, "teardown": {"duration": 0.00023744581267237663, "outcome": "passed", "stderr": "2025-06-05 12:45:03.462 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:stop:58 - youtube_transcripts module stopped\n"}}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_summarize_video_missing_params", "lineno": 200, "outcome": "passed", "keywords": ["test_summarize_video_missing_params", "asyncio", "pytestmark", "TestYoutubeTranscriptsStandardized", "test_youtube_transcripts_standardized.py", "level_0", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00037815794348716736, "outcome": "passed", "stderr": "2025-06-05 12:45:03.463 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:start:50 - youtube_transcripts module started successfully\n"}, "call": {"duration": 0.00019935518503189087, "outcome": "passed", "stderr": "2025-06-05 12:45:03.463 | ERROR    | youtube_transcripts.integrations.youtube_transcripts_module:process:83 - Error in youtube_transcripts: Either video_id or transcript is required\n"}, "teardown": {"duration": 0.00023861508816480637, "outcome": "passed", "stderr": "2025-06-05 12:45:03.463 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:stop:58 - youtube_transcripts module stopped\n"}}, {"nodeid": "tests/level_0/test_youtube_transcripts_standardized.py::TestYoutubeTranscriptsStandardized::test_multiple_actions_sequence", "lineno": 215, "outcome": "passed", "keywords": ["test_multiple_actions_sequence", "asyncio", "pytestmark", "TestYoutubeTranscriptsStandardized", "test_youtube_transcripts_standardized.py", "level_0", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0003821081481873989, "outcome": "passed", "stderr": "2025-06-05 12:45:03.464 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:start:50 - youtube_transcripts module started successfully\n"}, "call": {"duration": 0.00014876294881105423, "outcome": "passed"}, "teardown": {"duration": 0.00023367628455162048, "outcome": "passed", "stderr": "2025-06-05 12:45:03.464 | INFO     | youtube_transcripts.integrations.youtube_transcripts_module:stop:58 - youtube_transcripts module stopped\n"}}, {"nodeid": "tests/mcp/test_prompts.py::TestPromptRegistry::test_registry_creation", "lineno": 22, "outcome": "passed", "keywords": ["test_registry_creation", "TestPromptRegistry", "test_prompts.py", "mcp", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0002628760412335396, "outcome": "passed"}, "call": {"duration": 0.00011052330955862999, "outcome": "passed"}, "teardown": {"duration": 9.327195584774017e-05, "outcome": "passed"}}, {"nodeid": "tests/mcp/test_prompts.py::TestPromptRegistry::test_register_prompt", "lineno": 29, "outcome": "passed", "keywords": ["test_register_prompt", "TestPromptRegistry", "test_prompts.py", "mcp", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.547220543026924e-05, "outcome": "passed"}, "call": {"duration": 0.0001352829858660698, "outcome": "passed"}, "teardown": {"duration": 8.127233013510704e-05, "outcome": "passed"}}, {"nodeid": "tests/mcp/test_prompts.py::TestPromptRegistry::test_get_prompt", "lineno": 51, "outcome": "passed", "keywords": ["test_get_prompt", "TestPromptRegistry", "test_prompts.py", "mcp", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.33520495891571e-05, "outcome": "passed"}, "call": {"duration": 0.000134951900690794, "outcome": "passed"}, "teardown": {"duration": 7.944228127598763e-05, "outcome": "passed"}}, {"nodeid": "tests/mcp/test_prompts.py::TestPromptRegistry::test_execute_prompt", "lineno": 66, "outcome": "passed", "keywords": ["test_execute_prompt", "asyncio", "pytestmark", "TestPromptRegistry", "test_prompts.py", "mcp", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0001974143087863922, "outcome": "passed"}, "call": {"duration": 0.00026243599131703377, "outcome": "passed"}, "teardown": {"duration": 0.00016251392662525177, "outcome": "passed"}}, {"nodeid": "tests/mcp/test_prompts.py::TestPromptRegistry::test_execute_with_registry_injection", "lineno": 78, "outcome": "passed", "keywords": ["test_execute_with_registry_injection", "asyncio", "pytestmark", "TestPromptRegistry", "test_prompts.py", "mcp", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00019871490076184273, "outcome": "passed"}, "call": {"duration": 0.00017648376524448395, "outcome": "passed"}, "teardown": {"duration": 0.00014756293967366219, "outcome": "passed"}}, {"nodeid": "tests/mcp/test_prompts.py::TestPromptRegistry::test_prompt_parameters_extraction", "lineno": 91, "outcome": "passed", "keywords": ["test_prompt_parameters_extraction", "TestPromptRegistry", "test_prompts.py", "mcp", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00010005198419094086, "outcome": "passed"}, "call": {"duration": 0.00013597309589385986, "outcome": "passed"}, "teardown": {"duration": 8.161226287484169e-05, "outcome": "passed"}}, {"nodeid": "tests/mcp/test_prompts.py::TestMCPPromptDecorator::test_decorator_registration", "lineno": 124, "outcome": "passed", "keywords": ["test_decorator_registration", "TestMCPPromptDecorator", "test_prompts.py", "mcp", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.398208931088448e-05, "outcome": "passed"}, "call": {"duration": 0.00011926284059882164, "outcome": "passed"}, "teardown": {"duration": 8.26716423034668e-05, "outcome": "passed"}}, {"nodeid": "tests/mcp/test_prompts.py::TestMCPPromptDecorator::test_decorator_with_examples", "lineno": 146, "outcome": "passed", "keywords": ["test_decorator_with_examples", "TestMCPPromptDecorator", "test_prompts.py", "mcp", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.26721841096878e-05, "outcome": "passed"}, "call": {"duration": 0.0001176418736577034, "outcome": "passed"}, "teardown": {"duration": 8.056173101067543e-05, "outcome": "passed"}}, {"nodeid": "tests/mcp/test_prompts.py::TestFormatPromptResponse::test_basic_formatting", "lineno": 169, "outcome": "passed", "keywords": ["test_basic_formatting", "TestFormatPromptResponse", "test_prompts.py", "mcp", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.561190381646156e-05, "outcome": "passed"}, "call": {"duration": 0.00011847168207168579, "outcome": "passed"}, "teardown": {"duration": 7.975194603204727e-05, "outcome": "passed"}}, {"nodeid": "tests/mcp/test_prompts.py::TestFormatPromptResponse::test_formatting_with_next_steps", "lineno": 176, "outcome": "passed", "keywords": ["test_formatting_with_next_steps", "TestFormatPromptResponse", "test_prompts.py", "mcp", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.233178570866585e-05, "outcome": "passed"}, "call": {"duration": 0.00010354211553931236, "outcome": "passed"}, "teardown": {"duration": 7.90921039879322e-05, "outcome": "passed"}}, {"nodeid": "tests/mcp/test_prompts.py::TestFormatPromptResponse::test_formatting_with_suggestions", "lineno": 188, "outcome": "passed", "keywords": ["test_formatting_with_suggestions", "TestFormatPromptResponse", "test_prompts.py", "mcp", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0001063719391822815, "outcome": "passed"}, "call": {"duration": 0.0001062219962477684, "outcome": "passed"}, "teardown": {"duration": 7.854169234633446e-05, "outcome": "passed"}}, {"nodeid": "tests/mcp/test_prompts.py::TestFormatPromptResponse::test_formatting_with_data", "lineno": 203, "outcome": "failed", "keywords": ["test_formatting_with_data", "TestFormatPromptResponse", "test_prompts.py", "mcp", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.269220754504204e-05, "outcome": "passed"}, "call": {"duration": 0.0001782439649105072, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/mcp/test_prompts.py", "lineno": 215, "message": "assert '\"items\": [\"a\", \"b\"]' in 'Results\\n\\n## Data\\n```json\\n{\\n  \"count\": 42,\\n  \"items\": [\\n    \"a\",\\n    \"b\"\\n  ]\\n}\\n```'"}, "traceback": [{"path": "tests/mcp/test_prompts.py", "lineno": 215, "message": "in test_formatting_with_data"}], "longrepr": "tests/mcp/test_prompts.py:215: in test_formatting_with_data\n    assert '\"items\": [\"a\", \"b\"]' in response\nE   assert '\"items\": [\"a\", \"b\"]' in 'Results\\n\\n## Data\\n```json\\n{\\n  \"count\": 42,\\n  \"items\": [\\n    \"a\",\\n    \"b\"\\n  ]\\n}\\n```'"}, "teardown": {"duration": 9.89418476819992e-05, "outcome": "passed"}}, {"nodeid": "tests/mcp/test_prompts.py::TestMCPPromptSchema::test_prompt_to_schema", "lineno": 220, "outcome": "passed", "keywords": ["test_prompt_to_schema", "TestMCPPromptSchema", "test_prompts.py", "mcp", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.645288810133934e-05, "outcome": "passed"}, "call": {"duration": 0.00010623224079608917, "outcome": "passed"}, "teardown": {"duration": 9.089196100831032e-05, "outcome": "passed"}}, {"nodeid": "tests/mcp/test_prompts.py::TestMCPPromptSchema::test_registry_to_schema", "lineno": 241, "outcome": "passed", "keywords": ["test_registry_to_schema", "TestMCPPromptSchema", "test_prompts.py", "mcp", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.762216359376907e-05, "outcome": "passed"}, "call": {"duration": 0.00014398293569684029, "outcome": "passed"}, "teardown": {"duration": 8.028186857700348e-05, "outcome": "passed"}}, {"nodeid": "tests/mcp/test_prompts.py::test_full_prompt_workflow", "lineno": 263, "outcome": "failed", "keywords": ["test_full_prompt_workflow", "asyncio", "pytestmark", "test_prompts.py", "mcp", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00019784411415457726, "outcome": "passed"}, "call": {"duration": 0.00024956511333584785, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/mcp/test_prompts.py", "lineno": 298, "message": "AssertionError: assert '2 workflow prompts' in 'Processing... Found 0 workflow prompts'"}, "traceback": [{"path": "tests/mcp/test_prompts.py", "lineno": 298, "message": "in test_full_prompt_workflow"}], "longrepr": "tests/mcp/test_prompts.py:298: in test_full_prompt_workflow\n    assert \"2 workflow prompts\" in result2\nE   AssertionError: assert '2 workflow prompts' in 'Processing... Found 0 workflow prompts'"}, "teardown": {"duration": 0.00016166316345334053, "outcome": "passed"}}, {"nodeid": "tests/mcp/test_prompts.py::test_error_handling", "lineno": 301, "outcome": "passed", "keywords": ["test_error_handling", "asyncio", "pytestmark", "test_prompts.py", "mcp", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00020637409761548042, "outcome": "passed"}, "call": {"duration": 0.00023249536752700806, "outcome": "passed"}, "teardown": {"duration": 0.0001445426605641842, "outcome": "passed"}}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_1_basic_search", "lineno": 45, "outcome": "error", "keywords": ["test_scenario_1_basic_search", "TestLevel0Scenarios", "test_level0_scenarios.py", "scenarios", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0008324282243847847, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/scenarios/test_level0_scenarios.py", "lineno": 43, "message": "TypeError: UnifiedSearchConfig.__init__() got an unexpected keyword argument 'db_path'"}, "traceback": [{"path": "tests/scenarios/test_level0_scenarios.py", "lineno": 43, "message": "in youtube_client"}], "longrepr": "tests/scenarios/test_level0_scenarios.py:43: in youtube_client\n    config = UnifiedSearchConfig(db_path=test_db_path)\nE   TypeError: UnifiedSearchConfig.__init__() got an unexpected keyword argument 'db_path'"}, "teardown": {"duration": 0.00013106269761919975, "outcome": "passed"}}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_2_search_with_no_results", "lineno": 94, "outcome": "error", "keywords": ["test_scenario_2_search_with_no_results", "TestLevel0Scenarios", "test_level0_scenarios.py", "scenarios", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00043491926044225693, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/scenarios/test_level0_scenarios.py", "lineno": 43, "message": "TypeError: UnifiedSearchConfig.__init__() got an unexpected keyword argument 'db_path'"}, "traceback": [{"path": "tests/scenarios/test_level0_scenarios.py", "lineno": 43, "message": "in youtube_client"}], "longrepr": "tests/scenarios/test_level0_scenarios.py:43: in youtube_client\n    config = UnifiedSearchConfig(db_path=test_db_path)\nE   TypeError: UnifiedSearchConfig.__init__() got an unexpected keyword argument 'db_path'"}, "teardown": {"duration": 0.00013139285147190094, "outcome": "passed"}}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_3_search_widening", "lineno": 110, "outcome": "error", "keywords": ["test_scenario_3_search_widening", "TestLevel0Scenarios", "test_level0_scenarios.py", "scenarios", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00042109889909625053, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/scenarios/test_level0_scenarios.py", "lineno": 43, "message": "TypeError: UnifiedSearchConfig.__init__() got an unexpected keyword argument 'db_path'"}, "traceback": [{"path": "tests/scenarios/test_level0_scenarios.py", "lineno": 43, "message": "in youtube_client"}], "longrepr": "tests/scenarios/test_level0_scenarios.py:43: in youtube_client\n    config = UnifiedSearchConfig(db_path=test_db_path)\nE   TypeError: UnifiedSearchConfig.__init__() got an unexpected keyword argument 'db_path'"}, "teardown": {"duration": 0.00012497277930378914, "outcome": "passed"}}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_4_citation_extraction", "lineno": 136, "outcome": "passed", "keywords": ["test_scenario_4_citation_extraction", "TestLevel0Scenarios", "test_level0_scenarios.py", "scenarios", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.431177750229836e-05, "outcome": "passed"}, "call": {"duration": 10.651696256827563, "outcome": "passed"}, "teardown": {"duration": 0.00013539288192987442, "outcome": "passed"}}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_5_metadata_extraction", "lineno": 168, "outcome": "failed", "keywords": ["test_scenario_5_metadata_extraction", "TestLevel0Scenarios", "test_level0_scenarios.py", "scenarios", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00013266177847981453, "outcome": "passed"}, "call": {"duration": 0.3109083962626755, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/scenarios/test_level0_scenarios.py", "lineno": 187, "message": "AttributeError: 'MetadataExtractor' object has no attribute 'extract_all'. Did you mean: 'extract_urls'?"}, "traceback": [{"path": "tests/scenarios/test_level0_scenarios.py", "lineno": 187, "message": "in test_scenario_5_metadata_extraction"}], "longrepr": "tests/scenarios/test_level0_scenarios.py:187: in test_scenario_5_metadata_extraction\n    metadata = extractor.extract_all(test_transcript)\nE   AttributeError: 'MetadataExtractor' object has no attribute 'extract_all'. Did you mean: 'extract_urls'?"}, "teardown": {"duration": 0.00013857334852218628, "outcome": "passed"}}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_6_channel_filtering", "lineno": 204, "outcome": "error", "keywords": ["test_scenario_6_channel_filtering", "TestLevel0Scenarios", "test_level0_scenarios.py", "scenarios", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0005764318630099297, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/scenarios/test_level0_scenarios.py", "lineno": 43, "message": "TypeError: UnifiedSearchConfig.__init__() got an unexpected keyword argument 'db_path'"}, "traceback": [{"path": "tests/scenarios/test_level0_scenarios.py", "lineno": 43, "message": "in youtube_client"}], "longrepr": "tests/scenarios/test_level0_scenarios.py:43: in youtube_client\n    config = UnifiedSearchConfig(db_path=test_db_path)\nE   TypeError: UnifiedSearchConfig.__init__() got an unexpected keyword argument 'db_path'"}, "teardown": {"duration": 0.00014243274927139282, "outcome": "passed"}}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_7_youtube_api_search", "lineno": 236, "outcome": "error", "keywords": ["test_scenario_7_youtube_api_search", "TestLevel0Scenarios", "test_level0_scenarios.py", "scenarios", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0004520602524280548, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/scenarios/test_level0_scenarios.py", "lineno": 43, "message": "TypeError: UnifiedSearchConfig.__init__() got an unexpected keyword argument 'db_path'"}, "traceback": [{"path": "tests/scenarios/test_level0_scenarios.py", "lineno": 43, "message": "in youtube_client"}], "longrepr": "tests/scenarios/test_level0_scenarios.py:43: in youtube_client\n    config = UnifiedSearchConfig(db_path=test_db_path)\nE   TypeError: UnifiedSearchConfig.__init__() got an unexpected keyword argument 'db_path'"}, "teardown": {"duration": 0.00014245323836803436, "outcome": "passed"}}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_8_fetch_transcript", "lineno": 264, "outcome": "error", "keywords": ["test_scenario_8_fetch_transcript", "TestLevel0Scenarios", "test_level0_scenarios.py", "scenarios", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00043575000017881393, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/scenarios/test_level0_scenarios.py", "lineno": 43, "message": "TypeError: UnifiedSearchConfig.__init__() got an unexpected keyword argument 'db_path'"}, "traceback": [{"path": "tests/scenarios/test_level0_scenarios.py", "lineno": 43, "message": "in youtube_client"}], "longrepr": "tests/scenarios/test_level0_scenarios.py:43: in youtube_client\n    config = UnifiedSearchConfig(db_path=test_db_path)\nE   TypeError: UnifiedSearchConfig.__init__() got an unexpected keyword argument 'db_path'"}, "teardown": {"duration": 0.00017900392413139343, "outcome": "passed"}}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_9_search_pagination", "lineno": 287, "outcome": "error", "keywords": ["test_scenario_9_search_pagination", "TestLevel0Scenarios", "test_level0_scenarios.py", "scenarios", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0005145110189914703, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/scenarios/test_level0_scenarios.py", "lineno": 43, "message": "TypeError: UnifiedSearchConfig.__init__() got an unexpected keyword argument 'db_path'"}, "traceback": [{"path": "tests/scenarios/test_level0_scenarios.py", "lineno": 43, "message": "in youtube_client"}], "longrepr": "tests/scenarios/test_level0_scenarios.py:43: in youtube_client\n    config = UnifiedSearchConfig(db_path=test_db_path)\nE   TypeError: UnifiedSearchConfig.__init__() got an unexpected keyword argument 'db_path'"}, "teardown": {"duration": 0.00014627305790781975, "outcome": "passed"}}, {"nodeid": "tests/scenarios/test_level0_scenarios.py::TestLevel0Scenarios::test_scenario_10_scientific_classification", "lineno": 319, "outcome": "failed", "keywords": ["test_scenario_10_scientific_classification", "TestLevel0Scenarios", "test_level0_scenarios.py", "scenarios", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00011451169848442078, "outcome": "passed"}, "call": {"duration": 0.000425869133323431, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/scenarios/test_level0_scenarios.py", "lineno": 354, "message": "AttributeError: 'ContentClassifier' object has no attribute 'classify_content_type'. Did you mean: '_classify_content_type'?"}, "traceback": [{"path": "tests/scenarios/test_level0_scenarios.py", "lineno": 354, "message": "in test_scenario_10_scientific_classification"}], "longrepr": "tests/scenarios/test_level0_scenarios.py:354: in test_scenario_10_scientific_classification\n    content_type = classifier.classify_content_type(transcript)\nE   AttributeError: 'ContentClassifier' object has no attribute 'classify_content_type'. Did you mean: '_classify_content_type'?"}, "teardown": {"duration": 0.00010835332795977592, "outcome": "passed"}}, {"nodeid": "tests/test_arangodb_connection.py::test_connection", "lineno": 31, "outcome": "passed", "keywords": ["test_connection", "test_arangodb_connection.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00011197291314601898, "outcome": "passed"}, "call": {"duration": 0.011023176833987236, "outcome": "passed", "stderr": "2025-06-05 12:45:14.491 | INFO     | tests.test_arangodb_connection:test_connection:43 - Testing connection to http://localhost:8529\n2025-06-05 12:45:14.494 | SUCCESS  | tests.test_arangodb_connection:test_connection:53 - \u2705 Connection test passed\n2025-06-05 12:45:14.496 | SUCCESS  | tests.test_arangodb_connection:test_connection:71 - \u2705 Insert test passed - Document ID: transcripts/479793312\n2025-06-05 12:45:14.497 | SUCCESS  | tests.test_arangodb_connection:test_connection:80 - \u2705 Query test passed\n2025-06-05 12:45:14.499 | INFO     | tests.test_arangodb_connection:test_connection:91 - Full-text search returned 1 results\n2025-06-05 12:45:14.499 | SUCCESS  | tests.test_arangodb_connection:test_connection:92 - \u2705 Search view test passed\n2025-06-05 12:45:14.500 | SUCCESS  | tests.test_arangodb_connection:test_connection:96 - \u2705 Cleanup test passed\n2025-06-05 12:45:14.500 | INFO     | tests.test_arangodb_connection:test_connection:105 - \n============================================================\n2025-06-05 12:45:14.500 | SUCCESS  | tests.test_arangodb_connection:test_connection:106 - ALL TESTS PASSED! \ud83c\udf89\n2025-06-05 12:45:14.500 | INFO     | tests.test_arangodb_connection:test_connection:107 - ArangoDB is properly configured for YouTube transcripts\n2025-06-05 12:45:14.500 | INFO     | tests.test_arangodb_connection:test_connection:108 - ============================================================\n"}, "teardown": {"duration": 0.00014365417882800102, "outcome": "passed"}}, {"nodeid": "tests/test_integration_summary.py::test_integration", "lineno": 18, "outcome": "passed", "keywords": ["test_integration", "asyncio", "test_integration_summary.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00038014817982912064, "outcome": "passed"}, "call": {"duration": 2.1351763266138732, "outcome": "passed", "stdout": "YouTube Transcripts - Integration Test Summary\n============================================================\nDate: 2025-06-05T12:45:14.502406\n\n1. Testing SQLite Backend\n----------------------------------------\n\u2705 Stored 2 test videos\n\u2705 Search found 2 results\n\u2705 Found 0 supporting and 0 contradicting evidence\n\n2. Testing Dual Database Support\n----------------------------------------\nTesting backend auto-detection:\n\u2705 Default backend: SQLiteBackend\n\u2705 With prefer_arangodb: SQLiteBackend\n\n3. Key Features Summary\n----------------------------------------\n\u2705 Dual database support (SQLite/ArangoDB)\n\u2705 Bolster/Contradict functionality (matching arxiv-mcp-server)\n\u2705 Research analyzer with evidence finding\n\u2705 Database adapter pattern for seamless switching\n\u2705 Auto-detection of available backends\n\nReport saved to: /home/graham/workspace/experiments/youtube_transcripts/docs/reports/integration_test_summary.md\n"}, "teardown": {"duration": 0.0002397061325609684, "outcome": "passed"}}, {"nodeid": "tests/test_minimal.py::test_basic", "lineno": 2, "outcome": "passed", "keywords": ["test_basic", "test_minimal.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00011281203478574753, "outcome": "passed"}, "call": {"duration": 0.00011421181261539459, "outcome": "passed"}, "teardown": {"duration": 8.336221799254417e-05, "outcome": "passed"}}, {"nodeid": "tests/test_minimal.py::test_import_youtube_transcripts", "lineno": 6, "outcome": "passed", "keywords": ["test_import_youtube_transcripts", "test_minimal.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0001021423377096653, "outcome": "passed"}, "call": {"duration": 0.00010534189641475677, "outcome": "passed"}, "teardown": {"duration": 8.077220991253853e-05, "outcome": "passed"}}, {"nodeid": "tests/test_minimal.py::test_import_agents", "lineno": 11, "outcome": "passed", "keywords": ["test_import_agents", "test_minimal.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.736232459545135e-05, "outcome": "passed"}, "call": {"duration": 0.0001012217253446579, "outcome": "passed"}, "teardown": {"duration": 8.038198575377464e-05, "outcome": "passed"}}, {"nodeid": "tests/test_minimal.py::test_import_agent_manager", "lineno": 16, "outcome": "passed", "keywords": ["test_import_agent_manager", "test_minimal.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.44230705499649e-05, "outcome": "passed"}, "call": {"duration": 9.971205145120621e-05, "outcome": "passed"}, "teardown": {"duration": 8.135195821523666e-05, "outcome": "passed"}}, {"nodeid": "tests/test_reporter_verification.py::test_reporter_basic", "lineno": 6, "outcome": "passed", "keywords": ["test_reporter_basic", "test_reporter_verification.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.14321281015873e-05, "outcome": "passed"}, "call": {"duration": 9.627174586057663e-05, "outcome": "passed"}, "teardown": {"duration": 7.97719694674015e-05, "outcome": "passed"}}, {"nodeid": "tests/test_reporter_verification.py::test_reporter_with_output", "lineno": 11, "outcome": "passed", "keywords": ["test_reporter_with_output", "test_reporter_verification.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.503215551376343e-05, "outcome": "passed"}, "call": {"duration": 0.00012557301670312881, "outcome": "passed", "stdout": "Test output: Hello from test reporter\n"}, "teardown": {"duration": 7.904134690761566e-05, "outcome": "passed"}}, {"nodeid": "tests/test_reporter_verification.py::test_reporter_failure_example", "lineno": 18, "outcome": "failed", "keywords": ["test_reporter_failure_example", "test_reporter_verification.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.063165634870529e-05, "outcome": "passed"}, "call": {"duration": 0.00017610378563404083, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/test_reporter_verification.py", "lineno": 24, "message": "AssertionError: Expected 5 but got 4\nassert 4 == 5"}, "traceback": [{"path": "tests/test_reporter_verification.py", "lineno": 24, "message": "in test_reporter_failure_example"}], "longrepr": "tests/test_reporter_verification.py:24: in test_reporter_failure_example\n    assert actual == expected, f\"Expected {expected} but got {actual}\"\nE   AssertionError: Expected 5 but got 4\nE   assert 4 == 5"}, "teardown": {"duration": 9.63117927312851e-05, "outcome": "passed"}}, {"nodeid": "tests/test_reporter_verification.py::test_reporter_with_marker", "lineno": 26, "outcome": "passed", "keywords": ["test_reporter_with_marker", "slow", "pytestmark", "test_reporter_verification.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 9.530177339911461e-05, "outcome": "passed"}, "call": {"duration": 0.10032958723604679, "outcome": "passed"}, "teardown": {"duration": 0.00011535314843058586, "outcome": "passed"}}, {"nodeid": "tests/test_reporter_verification.py::TestReporterClass::test_class_method", "lineno": 37, "outcome": "passed", "keywords": ["test_class_method", "TestReporterClass", "test_reporter_verification.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00010532187297940254, "outcome": "passed"}, "call": {"duration": 0.00014982279390096664, "outcome": "passed"}, "teardown": {"duration": 7.769186049699783e-05, "outcome": "passed"}}, {"nodeid": "tests/test_reporter_verification.py::TestReporterClass::test_class_method_with_fixture", "lineno": 42, "outcome": "passed", "keywords": ["test_class_method_with_fixture", "TestReporterClass", "test_reporter_verification.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0005020010285079479, "outcome": "passed"}, "call": {"duration": 0.00021928409114480019, "outcome": "passed"}, "teardown": {"duration": 9.570224210619926e-05, "outcome": "passed"}}, {"nodeid": "tests/test_search_widening.py::TestSearchWidening::test_exact_match_no_widening", "lineno": 60, "outcome": "passed", "keywords": ["test_exact_match_no_widening", "TestSearchWidening", "test_search_widening.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0058056749403476715, "outcome": "passed"}, "call": {"duration": 0.0004445798695087433, "outcome": "passed"}, "teardown": {"duration": 0.0001589539460837841, "outcome": "passed"}}, {"nodeid": "tests/test_search_widening.py::TestSearchWidening::test_synonym_expansion", "lineno": 71, "outcome": "passed", "keywords": ["test_synonym_expansion", "TestSearchWidening", "test_search_widening.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00559111125767231, "outcome": "passed"}, "call": {"duration": 0.0013861898332834244, "outcome": "passed"}, "teardown": {"duration": 0.00014903303235769272, "outcome": "passed"}}, {"nodeid": "tests/test_search_widening.py::TestSearchWidening::test_fuzzy_matching", "lineno": 86, "outcome": "passed", "keywords": ["test_fuzzy_matching", "TestSearchWidening", "test_search_widening.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.005470627918839455, "outcome": "passed"}, "call": {"duration": 0.00040943920612335205, "outcome": "passed"}, "teardown": {"duration": 0.00014435360208153725, "outcome": "passed"}}, {"nodeid": "tests/test_search_widening.py::TestSearchWidening::test_no_results_after_widening", "lineno": 97, "outcome": "passed", "keywords": ["test_no_results_after_widening", "TestSearchWidening", "test_search_widening.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0054867882281541824, "outcome": "passed"}, "call": {"duration": 0.0012070457451045513, "outcome": "passed"}, "teardown": {"duration": 0.00018373364582657814, "outcome": "passed"}}, {"nodeid": "tests/test_search_widening.py::TestSearchWidening::test_widening_with_channels", "lineno": 107, "outcome": "passed", "keywords": ["test_widening_with_channels", "TestSearchWidening", "test_search_widening.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.005601551383733749, "outcome": "passed"}, "call": {"duration": 0.0013360879383981228, "outcome": "passed"}, "teardown": {"duration": 0.00017245300114154816, "outcome": "passed"}}, {"nodeid": "tests/test_search_widening.py::TestSearchWidening::test_semantic_expansion", "lineno": 120, "outcome": "passed", "keywords": ["test_semantic_expansion", "TestSearchWidening", "test_search_widening.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.006051140837371349, "outcome": "passed"}, "call": {"duration": 0.0026283557526767254, "outcome": "passed"}, "teardown": {"duration": 0.00016973307356238365, "outcome": "passed"}}, {"nodeid": "tests/test_search_widening.py::TestSearchWidening::test_widening_explanation", "lineno": 141, "outcome": "passed", "keywords": ["test_widening_explanation", "TestSearchWidening", "test_search_widening.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.0059683979488909245, "outcome": "passed"}, "call": {"duration": 0.0014861118979752064, "outcome": "passed"}, "teardown": {"duration": 0.00015140417963266373, "outcome": "passed"}}, {"nodeid": "tests/test_unified_search.py::TestUnifiedSearch::test_basic_search_without_optimization", "lineno": 74, "outcome": "failed", "keywords": ["test_basic_search_without_optimization", "TestUnifiedSearch", "test_unified_search.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.006786285899579525, "outcome": "passed"}, "call": {"duration": 0.0017972979694604874, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/test_unified_search.py", "lineno": 81, "message": "TypeError: UnifiedYouTubeSearch.__init__() got an unexpected keyword argument 'db_path'"}, "traceback": [{"path": "tests/test_unified_search.py", "lineno": 81, "message": "in test_basic_search_without_optimization"}], "longrepr": "tests/test_unified_search.py:81: in test_basic_search_without_optimization\n    search = UnifiedYouTubeSearch(config, db_path=test_db)\nE   TypeError: UnifiedYouTubeSearch.__init__() got an unexpected keyword argument 'db_path'"}, "teardown": {"duration": 0.00018582399934530258, "outcome": "passed"}}, {"nodeid": "tests/test_unified_search.py::TestUnifiedSearch::test_search_with_optimization", "lineno": 107, "outcome": "failed", "keywords": ["test_search_with_optimization", "TestUnifiedSearch", "test_unified_search.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.008006101939827204, "outcome": "passed"}, "call": {"duration": 0.0017902390100061893, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/test_unified_search.py", "lineno": 113, "message": "TypeError: UnifiedYouTubeSearch.__init__() got an unexpected keyword argument 'db_path'"}, "traceback": [{"path": "tests/test_unified_search.py", "lineno": 113, "message": "in test_search_with_optimization"}], "longrepr": "tests/test_unified_search.py:113: in test_search_with_optimization\n    search = UnifiedYouTubeSearch(config, db_path=test_db)\nE   TypeError: UnifiedYouTubeSearch.__init__() got an unexpected keyword argument 'db_path'"}, "teardown": {"duration": 0.00019581429660320282, "outcome": "passed"}}, {"nodeid": "tests/test_unified_search.py::TestUnifiedSearch::test_channel_specific_search", "lineno": 124, "outcome": "failed", "keywords": ["test_channel_specific_search", "TestUnifiedSearch", "test_unified_search.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.006809975951910019, "outcome": "passed"}, "call": {"duration": 0.0016846559010446072, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/test_unified_search.py", "lineno": 130, "message": "TypeError: UnifiedYouTubeSearch.__init__() got an unexpected keyword argument 'db_path'"}, "traceback": [{"path": "tests/test_unified_search.py", "lineno": 130, "message": "in test_channel_specific_search"}], "longrepr": "tests/test_unified_search.py:130: in test_channel_specific_search\n    search = UnifiedYouTubeSearch(config, db_path=test_db)\nE   TypeError: UnifiedYouTubeSearch.__init__() got an unexpected keyword argument 'db_path'"}, "teardown": {"duration": 0.0001710541546344757, "outcome": "passed"}}, {"nodeid": "tests/test_unified_search.py::TestUnifiedSearch::test_query_optimizer_directly", "lineno": 145, "outcome": "failed", "keywords": ["test_query_optimizer_directly", "TestUnifiedSearch", "test_unified_search.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.00011571310460567474, "outcome": "passed"}, "call": {"duration": 6.103133704978973, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/test_unified_search.py", "lineno": 165, "message": "assert '<think>\\nThe user\\'s query is very short and likely misspelled or incomplete. It appears they might be looking for a word related to \"VERL\". To optimize this search, I will make it more specific by assuming they meant \"verl\" which could refer to various terms like \"verified\", \"verify\", \"vernacular\", etc. Additionally, I\\'ll add some keywords that are commonly searched together with these terms, such as \"YouTube\" for context. This will help in retrieving the most relevant transcripts.\\n</think>\\n<answer>\\nverified+youtube+verl OR verify+youtube+verl OR vernacular+youtube+verl\\n[/ Your optimized query]\\n</answer>' == 'VERL'\n  \n  - VERL\n  + <think>\n  + The user's query is very short and likely misspelled or incomplete. It appears they might be looking for a word related to \"VERL\". To optimize this search, I will make it more specific by assuming they meant \"verl\" which could refer to various terms like \"verified\", \"verify\", \"vernacular\", etc. Additionally, I'll add some keywords that are commonly searched together with these terms, such as \"YouTube\" for context. This will help in retrieving the most relevant transcripts.\n  + </think>\n  + <answer>\n  + verified+youtube+verl OR verify+youtube+verl OR vernacular+youtube+verl\n  + [/ Your optimized query]\n  + </answer>"}, "traceback": [{"path": "tests/test_unified_search.py", "lineno": 165, "message": "in test_query_optimizer_directly"}], "log": [{"name": "youtube_transcripts.deepretrieval_optimizer", "msg": "Could not load LoRA adapter: No module named 'unsloth'", "args": null, "levelname": "WARNING", "levelno": 30, "pathname": "/home/graham/workspace/experiments/youtube_transcripts/src/youtube_transcripts/deepretrieval_optimizer.py", "filename": "deepretrieval_optimizer.py", "module": "deepretrieval_optimizer", "exc_info": null, "exc_text": null, "stack_info": null, "lineno": 67, "funcName": "_load_lora_adapter", "created": 1749141916.8581018, "msecs": 858.0, "relativeCreated": 58245.58067321777, "thread": 130816157991232, "threadName": "MainThread", "processName": "MainProcess", "process": 369085, "taskName": null}], "longrepr": "tests/test_unified_search.py:165: in test_query_optimizer_directly\n    assert result[\"original\"] == query\nE   assert '<think>\\nThe user\\'s query is very short and likely misspelled or incomplete. It appears they might be looking for a word related to \"VERL\". To optimize this search, I will make it more specific by assuming they meant \"verl\" which could refer to various terms like \"verified\", \"verify\", \"vernacular\", etc. Additionally, I\\'ll add some keywords that are commonly searched together with these terms, such as \"YouTube\" for context. This will help in retrieving the most relevant transcripts.\\n</think>\\n<answer>\\nverified+youtube+verl OR verify+youtube+verl OR vernacular+youtube+verl\\n[/ Your optimized query]\\n</answer>' == 'VERL'\nE     \nE     - VERL\nE     + <think>\nE     + The user's query is very short and likely misspelled or incomplete. It appears they might be looking for a word related to \"VERL\". To optimize this search, I will make it more specific by assuming they meant \"verl\" which could refer to various terms like \"verified\", \"verify\", \"vernacular\", etc. Additionally, I'll add some keywords that are commonly searched together with these terms, such as \"YouTube\" for context. This will help in retrieving the most relevant transcripts.\nE     + </think>\nE     + <answer>\nE     + verified+youtube+verl OR verify+youtube+verl OR vernacular+youtube+verl\nE     + [/ Your optimized query]\nE     + </answer>"}, "teardown": {"duration": 0.0001377630978822708, "outcome": "passed"}}, {"nodeid": "tests/test_unified_search.py::TestUnifiedSearch::test_empty_query_handling", "lineno": 169, "outcome": "failed", "keywords": ["test_empty_query_handling", "TestUnifiedSearch", "test_unified_search.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.007425160147249699, "outcome": "passed"}, "call": {"duration": 0.0018165991641581059, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/test_unified_search.py", "lineno": 175, "message": "TypeError: UnifiedYouTubeSearch.__init__() got an unexpected keyword argument 'db_path'"}, "traceback": [{"path": "tests/test_unified_search.py", "lineno": 175, "message": "in test_empty_query_handling"}], "longrepr": "tests/test_unified_search.py:175: in test_empty_query_handling\n    search = UnifiedYouTubeSearch(config, db_path=test_db)\nE   TypeError: UnifiedYouTubeSearch.__init__() got an unexpected keyword argument 'db_path'"}, "teardown": {"duration": 0.0001825941726565361, "outcome": "passed"}}, {"nodeid": "tests/test_unified_search.py::TestUnifiedSearch::test_multi_word_search", "lineno": 183, "outcome": "failed", "keywords": ["test_multi_word_search", "TestUnifiedSearch", "test_unified_search.py", "tests", "youtube_transcripts", ""], "setup": {"duration": 0.006839986890554428, "outcome": "passed"}, "call": {"duration": 0.0017561777494847775, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/youtube_transcripts/tests/test_unified_search.py", "lineno": 189, "message": "TypeError: UnifiedYouTubeSearch.__init__() got an unexpected keyword argument 'db_path'"}, "traceback": [{"path": "tests/test_unified_search.py", "lineno": 189, "message": "in test_multi_word_search"}], "longrepr": "tests/test_unified_search.py:189: in test_multi_word_search\n    search = UnifiedYouTubeSearch(config, db_path=test_db)\nE   TypeError: UnifiedYouTubeSearch.__init__() got an unexpected keyword argument 'db_path'"}, "teardown": {"duration": 0.00046032993122935295, "outcome": "passed"}}], "warnings": [{"message": "cannot collect test class 'TestReportGenerator' because it has a __init__ constructor (from: tests/integration/test_database_adapter.py)", "category": "PytestCollectionWarning", "when": "collect", "filename": "/home/graham/workspace/experiments/youtube_transcripts/tests/integration/test_database_adapter.py", "lineno": 35}, {"message": "Expected None, but tests/test_arangodb_connection.py::test_connection returned True, which will be an error in a future version of pytest.  Did you mean to use `assert` instead of `return`?", "category": "PytestReturnNotNoneWarning", "when": "runtest", "filename": "/home/graham/workspace/experiments/youtube_transcripts/.venv/lib/python3.12/site-packages/_pytest/python.py", "lineno": 163}]}